{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hw-oh/wandb_e2e_demo/blob/main/models/image_detection/image_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q wandb ultralytics wandb-workspaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "WANDB_API_KEY = userdata.get(\"WANDB_API_KEY\")\n",
        "WANDB_ENTITY = userdata.get(\"WANDB_ENTITY\")\n",
        "WANDB_PROJECT = userdata.get(\"WANDB_PROJECT\")\n",
        "WANDB_REGISTRY_NAME = userdata.get(\"WANDB_REGISTRY_NAME\")\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "print(f\"Entity: {WANDB_ENTITY}\")\n",
        "print(f\"Project: {WANDB_PROJECT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unified Vision Demo — YOLOv8-seg로 Classification + Detection + Segmentation\n",
        "\n",
        "## 개요\n",
        "\n",
        "이 노트북은 **COCO128-seg** 데이터셋과 **YOLOv8n-seg** 모델을 사용하여\n",
        "하나의 모델로 **Classification(분류)**, **Detection(탐지)**, **Segmentation(분할)** 을\n",
        "모두 수행하면서 W&B의 핵심 기능을 전부 체험합니다.\n",
        "\n",
        "### 왜 YOLOv8-seg인가?\n",
        "\n",
        "YOLOv8-seg는 한 번의 추론으로 세 가지 결과를 동시에 제공합니다:\n",
        "- **Classification**: 검출된 객체의 클래스 분류\n",
        "- **Detection**: 바운딩 박스 좌표 + 클래스 + 신뢰도\n",
        "- **Segmentation**: 인스턴스별 픽셀 마스크\n",
        "\n",
        "## 다루는 W&B 기능\n",
        "\n",
        "| 기능 | 설명 |\n",
        "|------|------|\n",
        "| **Experiment Tracking** | 학습 메트릭 실시간 추적 (`wandb.init`, `wandb.log`, `wandb.config`) |\n",
        "| **Media Logging** | BBox + Mask 시각화 (`wandb.Image`) |\n",
        "| **Tables** | 데이터셋 미리보기 및 예측 결과 비교 (`wandb.Table`) |\n",
        "| **Artifacts** | 데이터셋/모델 버저닝 및 계보(lineage) 추적 |\n",
        "| **Model Registry** | 모델 등록 및 alias 관리 (staging → production) |\n",
        "| **Sweeps** | 베이지안 하이퍼파라미터 최적화 + 튜닝 효과 검증 |\n",
        "| **Reports** | 프로그래밍 방식 실험 리포트 생성 |\n",
        "\n",
        "## 데이터셋\n",
        "- **COCO128-seg**: COCO 데이터셋의 소형 서브셋 (128장, 80 classes, 인스턴스 세그멘테이션 라벨 포함)\n",
        "- Ultralytics 내장 — 자동 다운로드\n",
        "\n",
        "## 모델\n",
        "- **YOLOv8n-seg** (nano segmentation) — Ultralytics pretrained on COCO\n",
        "- Detection + Instance Segmentation 통합 모델\n",
        "- Colab T4에서 빠른 학습, Streamlit Cloud(CPU)에서 추론 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import yaml\n",
        "import csv\n",
        "\n",
        "BASELINE_CONFIG = {\n",
        "    \"model_name\": \"yolov8n-seg\",\n",
        "    \"dataset\": \"coco128-seg\",\n",
        "    \"epochs\": 30,\n",
        "    \"imgsz\": 640,\n",
        "    \"lr0\": 0.01,\n",
        "    \"batch\": 16,\n",
        "    \"num_classes\": 80,\n",
        "}\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
        "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
        "    \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n",
        "    \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "    \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\",\n",
        "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
        "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\",\n",
        "]\n",
        "\n",
        "CLASS_LABELS = {i: name for i, name in enumerate(COCO_CLASSES)}\n",
        "\n",
        "print(f\"COCO classes: {len(COCO_CLASSES)}개\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 데이터셋 준비 + Artifact 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_info = check_det_dataset(\"coco128-seg.yaml\")\n",
        "DATASET_DIR = data_info[\"path\"]\n",
        "print(f\"데이터셋 경로: {DATASET_DIR}\")\n",
        "\n",
        "train_images = glob.glob(f\"{DATASET_DIR}/images/train2017/*.jpg\")\n",
        "print(f\"Train 이미지: {len(train_images)}장\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"data-versioning\",\n",
        "    name=\"coco128-seg-data-versioning\",\n",
        ")\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    \"coco128-seg\",\n",
        "    type=\"dataset\",\n",
        "    description=\"COCO128-seg dataset (128 images, 80 classes, instance segmentation labels)\",\n",
        "    metadata={\n",
        "        \"num_images\": len(train_images),\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"format\": \"YOLO-seg\",\n",
        "        \"source\": \"Ultralytics COCO128-seg\",\n",
        "    },\n",
        ")\n",
        "artifact.add_dir(DATASET_DIR)\n",
        "run.log_artifact(artifact)\n",
        "print(\"데이터셋 Artifact 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_yolo_label(label_path, img_w, img_h):\n",
        "    \"\"\"YOLO-seg format 라벨에서 BBox를 wandb box_data로 변환한다.\"\"\"\n",
        "    box_data = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return box_data\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cls_id = int(parts[0])\n",
        "            x_c, y_c, w, h = float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
        "            box_data.append({\n",
        "                \"position\": {\"middle\": [x_c, y_c], \"width\": w, \"height\": h},\n",
        "                \"class_id\": cls_id,\n",
        "                \"box_caption\": COCO_CLASSES[cls_id] if cls_id < len(COCO_CLASSES) else str(cls_id),\n",
        "            })\n",
        "    return box_data\n",
        "\n",
        "\n",
        "table = wandb.Table(columns=[\"Image with BBox\", \"Image\", \"Num Objects\", \"Classes\"])\n",
        "\n",
        "sample_images = random.sample(train_images, min(20, len(train_images)))\n",
        "\n",
        "for img_path in sample_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "    box_data = parse_yolo_label(label_path, img_w, img_h)\n",
        "\n",
        "    img_with_boxes = wandb.Image(\n",
        "        img,\n",
        "        boxes={\n",
        "            \"ground_truth\": {\n",
        "                \"box_data\": box_data,\n",
        "                \"class_labels\": CLASS_LABELS,\n",
        "            }\n",
        "        } if box_data else {},\n",
        "    )\n",
        "\n",
        "    class_names = list({bd[\"box_caption\"] for bd in box_data})\n",
        "    table.add_data(img_with_boxes, wandb.Image(img), len(box_data), \", \".join(class_names))\n",
        "\n",
        "wandb.log({\"dataset_preview\": table})\n",
        "wandb.finish()\n",
        "print(\"데이터셋 미리보기 테이블 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Baseline 학습 — 기본 하이퍼파라미터\n",
        "\n",
        "먼저 기본 하이퍼파라미터(`lr0=0.01`, `batch=16`)로 YOLOv8n-seg를 학습합니다.\n",
        "이 결과를 기준점(baseline)으로 삼아, 뒤에서 Sweep을 통해 얼마나 개선되는지 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"training\",\n",
        "    name=\"baseline-yolov8n-seg\",\n",
        "    tags=[\"baseline\"],\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128-seg:latest\")\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=BASELINE_CONFIG[\"imgsz\"],\n",
        "    lr0=BASELINE_CONFIG[\"lr0\"],\n",
        "    batch=BASELINE_CONFIG[\"batch\"],\n",
        "    project=\"runs/segment\",\n",
        "    name=\"baseline\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "csv_path = os.path.join(results.save_dir, \"results.csv\")\n",
        "if os.path.exists(csv_path):\n",
        "    with open(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            row = {k.strip(): v.strip() for k, v in row.items()}\n",
        "            wandb.log({\n",
        "                \"epoch\": int(row[\"epoch\"]),\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]),\n",
        "                \"train/seg_loss\": float(row[\"train/seg_loss\"]),\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]),\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]),\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]),\n",
        "                \"val/seg_loss\": float(row[\"val/seg_loss\"]),\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]),\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]),\n",
        "                \"val/mAP50_box\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"val/mAP50-95_box\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "                \"val/precision_box\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"val/recall_box\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"val/mAP50_mask\": float(row[\"metrics/mAP50(M)\"]),\n",
        "                \"val/mAP50-95_mask\": float(row[\"metrics/mAP50-95(M)\"]),\n",
        "            })\n",
        "\n",
        "BASELINE_BEST_PT = os.path.join(results.save_dir, \"weights/best.pt\")\n",
        "baseline_metrics = results.results_dict\n",
        "baseline_mAP50_box = baseline_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "baseline_mAP50_mask = baseline_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"Baseline 학습 완료!\")\n",
        "print(f\"  mAP50 (Box):  {baseline_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {baseline_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = YOLO(BASELINE_BEST_PT)\n",
        "sample_for_viz = random.sample(train_images, min(16, len(train_images)))\n",
        "\n",
        "det_images = []\n",
        "seg_images = []\n",
        "for img_path in sample_for_viz:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "    preds = best_model(img_path, verbose=False)\n",
        "    r = preds[0]\n",
        "\n",
        "    box_data = []\n",
        "    for box in r.boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        box_data.append({\n",
        "            \"position\": {\n",
        "                \"minX\": x1 / img_w, \"minY\": y1 / img_h,\n",
        "                \"maxX\": x2 / img_w, \"maxY\": y2 / img_h,\n",
        "            },\n",
        "            \"class_id\": int(box.cls),\n",
        "            \"scores\": {\"confidence\": float(box.conf)},\n",
        "            \"box_caption\": f\"{COCO_CLASSES[int(box.cls)]} {float(box.conf):.2f}\",\n",
        "        })\n",
        "\n",
        "    det_images.append(wandb.Image(\n",
        "        img,\n",
        "        boxes={\"predictions\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "    ))\n",
        "\n",
        "    rendered = Image.fromarray(r.plot()[..., ::-1])\n",
        "    seg_images.append(wandb.Image(rendered, caption=f\"{len(r.boxes)}개 객체\"))\n",
        "\n",
        "wandb.log({\"baseline/detection_results\": det_images})\n",
        "wandb.log({\"baseline/segmentation_results\": seg_images})\n",
        "print(f\"{len(sample_for_viz)}장에 대한 Detection + Segmentation 시각화 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_table = wandb.Table(columns=[\n",
        "    \"Detection\", \"Seg Overlay\", \"Num Objects\", \"Detected Classes\", \"Avg Confidence\",\n",
        "])\n",
        "\n",
        "eval_images = random.sample(train_images, min(30, len(train_images)))\n",
        "\n",
        "for img_path in eval_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "    preds = best_model(img_path, verbose=False)\n",
        "    r = preds[0]\n",
        "\n",
        "    box_data = []\n",
        "    detected_classes = set()\n",
        "    confs = []\n",
        "    for box in r.boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        box_data.append({\n",
        "            \"position\": {\n",
        "                \"minX\": x1 / img_w, \"minY\": y1 / img_h,\n",
        "                \"maxX\": x2 / img_w, \"maxY\": y2 / img_h,\n",
        "            },\n",
        "            \"class_id\": cls_id,\n",
        "            \"scores\": {\"confidence\": conf},\n",
        "            \"box_caption\": f\"{COCO_CLASSES[cls_id]} {conf:.2f}\",\n",
        "        })\n",
        "        detected_classes.add(COCO_CLASSES[cls_id])\n",
        "        confs.append(conf)\n",
        "\n",
        "    det_img = wandb.Image(\n",
        "        img,\n",
        "        boxes={\"predictions\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "    )\n",
        "    seg_overlay = wandb.Image(Image.fromarray(r.plot()[..., ::-1]))\n",
        "    avg_conf = np.mean(confs) if confs else 0.0\n",
        "\n",
        "    pred_table.add_data(\n",
        "        det_img, seg_overlay, len(r.boxes),\n",
        "        \", \".join(sorted(detected_classes)), f\"{avg_conf:.2%}\",\n",
        "    )\n",
        "\n",
        "wandb.log({\"baseline/prediction_table\": pred_table})\n",
        "print(f\"예측 결과 테이블 ({len(eval_images)}장) 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_artifact = wandb.Artifact(\n",
        "    \"yolov8n-seg-coco128\",\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg baseline on COCO128-seg (default hyperparameters)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": baseline_mAP50_box,\n",
        "        \"best_mAP50_mask\": baseline_mAP50_mask,\n",
        "        \"sweep_tuned\": False,\n",
        "    },\n",
        ")\n",
        "baseline_artifact.add_file(BASELINE_BEST_PT, name=\"best.pt\")\n",
        "run.log_artifact(baseline_artifact)\n",
        "\n",
        "run.link_artifact(\n",
        "    baseline_artifact,\n",
        "    f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "    aliases=[\"baseline\"],\n",
        ")\n",
        "print(\"Baseline 모델을 Registry에 'baseline' alias로 등록 완료!\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. W&B Sweep — 하이퍼파라미터 최적화\n",
        "\n",
        "W&B Sweeps의 **베이지안 최적화**를 사용하여 최적의 하이퍼파라미터를 탐색합니다.\n",
        "Sweep을 여러 번 돌리면서 최적의 조합을 찾아가는 과정을 관찰하세요.\n",
        "\n",
        "**탐색 파라미터:**\n",
        "- `lr0`: 초기 학습률 (0.001 ~ 0.02)\n",
        "- `lrf`: 최종 학습률 비율 (0.01 ~ 0.2)\n",
        "- `momentum`: SGD 모멘텀 (0.85 ~ 0.98)\n",
        "- `weight_decay`: 가중치 감쇠 (0.0001 ~ 0.001)\n",
        "- `warmup_epochs`: 웜업 에포크 수 (1, 2, 3)\n",
        "- `mosaic`: 모자이크 증강 비율 (0.5 ~ 1.0)\n",
        "\n",
        "**최적화 목표:** `val/mAP50_box` 최대화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val/mAP50_box\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"lr0\": {\"min\": 0.001, \"max\": 0.02},\n",
        "        \"lrf\": {\"min\": 0.01, \"max\": 0.2},\n",
        "        \"momentum\": {\"min\": 0.85, \"max\": 0.98},\n",
        "        \"weight_decay\": {\"min\": 0.0001, \"max\": 0.001},\n",
        "        \"warmup_epochs\": {\"values\": [1, 2, 3]},\n",
        "        \"mosaic\": {\"min\": 0.5, \"max\": 1.0},\n",
        "    },\n",
        "}\n",
        "\n",
        "SWEEP_EPOCHS = 10\n",
        "\n",
        "\n",
        "def sweep_train():\n",
        "    run = wandb.init()\n",
        "    cfg = wandb.config\n",
        "\n",
        "    sweep_model = YOLO(\"yolov8n-seg.pt\")\n",
        "    sweep_results = sweep_model.train(\n",
        "        data=\"coco128-seg.yaml\",\n",
        "        epochs=SWEEP_EPOCHS,\n",
        "        imgsz=640,\n",
        "        lr0=cfg.lr0,\n",
        "        lrf=cfg.lrf,\n",
        "        momentum=cfg.momentum,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "        warmup_epochs=cfg.warmup_epochs,\n",
        "        mosaic=cfg.mosaic,\n",
        "        batch=16,\n",
        "        project=\"runs/segment_sweep\",\n",
        "        name=f\"sweep_{run.id}\",\n",
        "        exist_ok=True,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    metrics = sweep_results.results_dict\n",
        "    wandb.log({\n",
        "        \"val/mAP50_box\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "        \"val/mAP50-95_box\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        \"val/precision_box\": metrics.get(\"metrics/precision(B)\", 0),\n",
        "        \"val/recall_box\": metrics.get(\"metrics/recall(B)\", 0),\n",
        "        \"val/mAP50_mask\": metrics.get(\"metrics/mAP50(M)\", 0),\n",
        "        \"val/mAP50-95_mask\": metrics.get(\"metrics/mAP50-95(M)\", 0),\n",
        "    })\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=10)\n",
        "print(\"Sweep 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Sweep 최적 하이퍼파라미터로 Full Training\n",
        "\n",
        "Sweep에서 찾은 최적의 하이퍼파라미터로 full epoch 학습을 실행합니다.\n",
        "Baseline과 비교하여 Sweep의 효과를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "sweep = api.sweep(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{sweep_id}\")\n",
        "best_run = sweep.best_run()\n",
        "best_config = best_run.config\n",
        "\n",
        "print(\"Sweep 최적 하이퍼파라미터:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"  Best mAP50 (Box): {best_run.summary.get('val/mAP50_box', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_config = {**BASELINE_CONFIG, **best_config}\n",
        "tuned_config[\"sweep_tuned\"] = True\n",
        "tuned_config[\"sweep_id\"] = sweep_id\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=tuned_config,\n",
        "    job_type=\"training\",\n",
        "    name=\"tuned-yolov8n-seg\",\n",
        "    tags=[\"sweep-tuned\"],\n",
        ")\n",
        "\n",
        "tuned_model = YOLO(\"yolov8n-seg.pt\")\n",
        "tuned_results = tuned_model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=640,\n",
        "    lr0=best_config.get(\"lr0\", 0.01),\n",
        "    lrf=best_config.get(\"lrf\", 0.01),\n",
        "    momentum=best_config.get(\"momentum\", 0.937),\n",
        "    weight_decay=best_config.get(\"weight_decay\", 0.0005),\n",
        "    warmup_epochs=best_config.get(\"warmup_epochs\", 3),\n",
        "    mosaic=best_config.get(\"mosaic\", 1.0),\n",
        "    batch=16,\n",
        "    project=\"runs/segment\",\n",
        "    name=\"tuned\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "csv_path = os.path.join(tuned_results.save_dir, \"results.csv\")\n",
        "if os.path.exists(csv_path):\n",
        "    with open(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            row = {k.strip(): v.strip() for k, v in row.items()}\n",
        "            wandb.log({\n",
        "                \"epoch\": int(row[\"epoch\"]),\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]),\n",
        "                \"train/seg_loss\": float(row[\"train/seg_loss\"]),\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]),\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]),\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]),\n",
        "                \"val/seg_loss\": float(row[\"val/seg_loss\"]),\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]),\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]),\n",
        "                \"val/mAP50_box\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"val/mAP50-95_box\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "                \"val/precision_box\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"val/recall_box\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"val/mAP50_mask\": float(row[\"metrics/mAP50(M)\"]),\n",
        "                \"val/mAP50-95_mask\": float(row[\"metrics/mAP50-95(M)\"]),\n",
        "            })\n",
        "\n",
        "TUNED_BEST_PT = os.path.join(tuned_results.save_dir, \"weights/best.pt\")\n",
        "tuned_metrics = tuned_results.results_dict\n",
        "tuned_mAP50_box = tuned_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "tuned_mAP50_mask = tuned_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"\\nTuned 학습 완료!\")\n",
        "print(f\"  mAP50 (Box):  {tuned_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {tuned_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Baseline vs Sweep-Tuned 비교\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "box_diff = tuned_mAP50_box - baseline_mAP50_box\n",
        "mask_diff = tuned_mAP50_mask - baseline_mAP50_mask\n",
        "\n",
        "print(f\"{'Metric':<20} {'Baseline':>10} {'Tuned':>10} {'Diff':>10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'mAP50 (Box)':<20} {baseline_mAP50_box:>10.4f} {tuned_mAP50_box:>10.4f} {box_diff:>+10.4f}\")\n",
        "print(f\"{'mAP50 (Mask)':<20} {baseline_mAP50_mask:>10.4f} {tuned_mAP50_mask:>10.4f} {mask_diff:>+10.4f}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"comparison/baseline_mAP50_box\": baseline_mAP50_box,\n",
        "    \"comparison/tuned_mAP50_box\": tuned_mAP50_box,\n",
        "    \"comparison/improvement_mAP50_box\": box_diff,\n",
        "    \"comparison/baseline_mAP50_mask\": baseline_mAP50_mask,\n",
        "    \"comparison/tuned_mAP50_mask\": tuned_mAP50_mask,\n",
        "    \"comparison/improvement_mAP50_mask\": mask_diff,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mAP50 = max(tuned_mAP50_box, baseline_mAP50_box)\n",
        "final_mAP50_mask = max(tuned_mAP50_mask, baseline_mAP50_mask)\n",
        "final_pt = TUNED_BEST_PT if tuned_mAP50_box >= baseline_mAP50_box else BASELINE_BEST_PT\n",
        "is_tuned_better = tuned_mAP50_box >= baseline_mAP50_box\n",
        "\n",
        "print(f\"최종 모델: {'Tuned' if is_tuned_better else 'Baseline'} (mAP50 Box: {final_mAP50:.4f})\")\n",
        "\n",
        "model_artifact = wandb.Artifact(\n",
        "    \"yolov8n-seg-coco128\",\n",
        "    type=\"model\",\n",
        "    description=f\"YOLOv8n-seg {'sweep-tuned' if is_tuned_better else 'baseline'} on COCO128-seg\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": final_mAP50,\n",
        "        \"best_mAP50_mask\": final_mAP50_mask,\n",
        "        \"sweep_tuned\": is_tuned_better,\n",
        "    },\n",
        ")\n",
        "model_artifact.add_file(final_pt, name=\"best.pt\")\n",
        "run.log_artifact(model_artifact)\n",
        "\n",
        "run.link_artifact(\n",
        "    model_artifact,\n",
        "    f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "    aliases=[\"staging\"],\n",
        ")\n",
        "print(\"최종 모델을 Registry에 'staging' alias로 등록 완료!\")\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. W&B Report 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb_workspaces.reports.v2 as wr\n",
        "\n",
        "report = wr.Report(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    title=\"Unified Vision — YOLOv8n-seg 실험 결과 리포트\",\n",
        "    description=\"YOLOv8n-seg COCO128 학습 + Sweep 하이퍼파라미터 튜닝 결과\",\n",
        ")\n",
        "\n",
        "report.blocks = [\n",
        "    wr.TableOfContents(),\n",
        "\n",
        "    wr.H1(\"1. 실험 개요\"),\n",
        "    wr.P(\n",
        "        \"COCO128-seg 데이터셋에 대한 YOLOv8n-seg 통합 비전 모델 실험 결과를 정리합니다. \"\n",
        "        \"하나의 모델로 Classification, Detection, Segmentation을 모두 수행합니다. \"\n",
        "        \"W&B의 Experiment Tracking, Artifacts, Sweeps, Model Registry, Media Logging 기능을 활용하였습니다.\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"2. Baseline 학습 결과\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[\n",
        "            wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)\n",
        "        ],\n",
        "        panels=[\n",
        "            wr.LinePlot(title=\"Box Loss (Train)\", x=\"epoch\", y=[\"train/box_loss\"]),\n",
        "            wr.LinePlot(title=\"Seg Loss (Train)\", x=\"epoch\", y=[\"train/seg_loss\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Box)\", x=\"epoch\", y=[\"val/mAP50_box\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Mask)\", x=\"epoch\", y=[\"val/mAP50_mask\"]),\n",
        "            wr.LinePlot(title=\"Precision (Box)\", x=\"epoch\", y=[\"val/precision_box\"]),\n",
        "            wr.LinePlot(title=\"Recall (Box)\", x=\"epoch\", y=[\"val/recall_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"3. Sweep 분석\"),\n",
        "    wr.P(\"Bayesian 최적화를 통한 하이퍼파라미터 탐색 결과:\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[\n",
        "            wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)\n",
        "        ],\n",
        "        panels=[\n",
        "            wr.ParallelCoordinatesPlot(\n",
        "                columns=[\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lr0\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lrf\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::momentum\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::weight_decay\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::mosaic\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"val/mAP50_box\"),\n",
        "                ],\n",
        "            ),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Box)\", metric=\"val/mAP50_box\"),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Mask)\", metric=\"val/mAP50_mask\"),\n",
        "            wr.BarPlot(title=\"mAP@0.5 by Run\", metrics=[\"val/mAP50_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"4. Baseline vs Sweep-Tuned 비교\"),\n",
        "    wr.P(\n",
        "        f\"Baseline mAP50 (Box): {baseline_mAP50_box:.4f} → \"\n",
        "        f\"Tuned mAP50 (Box): {tuned_mAP50_box:.4f} \"\n",
        "        f\"(차이: {box_diff:+.4f})\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"5. 다음 단계\"),\n",
        "    wr.P(\n",
        "        \"최적 모델을 Model Registry의 'production' alias로 승격하여 \"\n",
        "        \"Automation → GitHub Actions → Streamlit 배포 파이프라인을 트리거합니다.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "report.save()\n",
        "print(f\"Report 생성 완료! URL: {report.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Production 승격 (Automation 트리거)\n",
        "\n",
        "아래 셀을 실행하면 Model Registry에서 최신 모델을 `production` alias로 승격합니다.\n",
        "\n",
        "W&B Automation이 설정되어 있으면:\n",
        "1. `production` alias 추가 이벤트 발생\n",
        "2. Webhook → GitHub `repository_dispatch` 트리거\n",
        "3. GitHub Actions가 `deployment.json` 업데이트 → git push\n",
        "4. Streamlit Cloud 앱이 새 모델로 자동 배포\n",
        "\n",
        "**참고**: W&B UI에서 수동으로 `production` alias를 추가해도 동일하게 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "artifact_path = f\"{WANDB_ENTITY}/{WANDB_PROJECT}/yolov8n-seg-coco128:latest\"\n",
        "\n",
        "try:\n",
        "    art = api.artifact(artifact_path)\n",
        "    art.aliases.append(\"production\")\n",
        "    art.save()\n",
        "    print(f\"'{artifact_path}'에 'production' alias 추가 완료!\")\n",
        "    print(\"W&B Automation이 설정되어 있으면 배포 파이프라인이 자동으로 트리거됩니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"Production 승격 실패: {e}\")\n",
        "    print(\"W&B UI에서 수동으로 'production' alias를 추가해 주세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n",
        "print(\"모든 W&B 리소스가 정리되었습니다. 데모 완료!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
