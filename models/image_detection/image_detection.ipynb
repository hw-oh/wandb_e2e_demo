{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7HTRZUbTftE"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hw-oh/wandb_e2e_demo/blob/main/models/image_detection/image_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eehEyItBTftF",
        "outputId": "6272b8ac-799b-4d9e-a070-30240a028b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/96.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q wandb ultralytics wandb-workspaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKh0i08uTftG",
        "outputId": "c06bc023-2024-49de-d511-d57863f29529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyunwoo-oh\u001b[0m (\u001b[33mwandb-korea\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: wandb-korea\n",
            "Project: e2e-cv-demo\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import wandb\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "WANDB_API_KEY = userdata.get(\"WANDB_API_KEY\")\n",
        "WANDB_ENTITY = userdata.get(\"WANDB_ENTITY\")\n",
        "WANDB_PROJECT = userdata.get(\"WANDB_PROJECT\")\n",
        "WANDB_REGISTRY_NAME = userdata.get(\"WANDB_REGISTRY_NAME\")\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "print(f\"Entity: {WANDB_ENTITY}\")\n",
        "print(f\"Project: {WANDB_PROJECT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyO3uqr2TftG"
      },
      "source": [
        "# Unified Vision Demo â€” YOLOv8-segë¡œ Classification + Detection + Segmentation\n",
        "\n",
        "## ê°œìš”\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ **COCO128-seg** ë°ì´í„°ì…‹ê³¼ **YOLOv8n-seg** ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬\n",
        "í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ **Classification(ë¶„ë¥˜)**, **Detection(íƒì§€)**, **Segmentation(ë¶„í• )** ì„\n",
        "ëª¨ë‘ ìˆ˜í–‰í•˜ë©´ì„œ W&Bì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì „ë¶€ ì²´í—˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ì™œ YOLOv8-segì¸ê°€?\n",
        "\n",
        "YOLOv8-segëŠ” í•œ ë²ˆì˜ ì¶”ë¡ ìœ¼ë¡œ ì„¸ ê°€ì§€ ê²°ê³¼ë¥¼ ë™ì‹œì— ì œê³µí•©ë‹ˆë‹¤:\n",
        "- **Classification**: ê²€ì¶œëœ ê°ì²´ì˜ í´ë˜ìŠ¤ ë¶„ë¥˜\n",
        "- **Detection**: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ + í´ë˜ìŠ¤ + ì‹ ë¢°ë„\n",
        "- **Segmentation**: ì¸ìŠ¤í„´ìŠ¤ë³„ í”½ì…€ ë§ˆìŠ¤í¬\n",
        "\n",
        "### ëª¨ë¸ ë²„ì „ ê´€ë¦¬ íë¦„\n",
        "\n",
        "| ë‹¨ê³„ | Artifact Alias | ì„¤ëª… |\n",
        "|------|---------------|------|\n",
        "| Xavier ì´ˆê¸°í™” | `xavier-init` | í•™ìŠµ ì „ ëœë¤ ì´ˆê¸°í™” ëª¨ë¸ (ê¸°ì¤€ì ) |\n",
        "| Baseline í•™ìŠµ | `baseline` | ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ |\n",
        "| Sweep ìµœì í™” | `latest` | Sweepìœ¼ë¡œ ì°¾ì€ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ |\n",
        "\n",
        "## ë‹¤ë£¨ëŠ” W&B ê¸°ëŠ¥\n",
        "\n",
        "| ê¸°ëŠ¥ | ì„¤ëª… |\n",
        "|------|------|\n",
        "| **Experiment Tracking** | í•™ìŠµ ë©”íŠ¸ë¦­ ì‹¤ì‹œê°„ ì¶”ì  (`wandb.init`, `wandb.log`, `wandb.config`) |\n",
        "| **Media Logging** | BBox + Mask ì¸í„°ë™í‹°ë¸Œ ì‹œê°í™” (`wandb.Image`) |\n",
        "| **Tables** | ì˜ˆì¸¡ ê²°ê³¼ + mIoU ë¹„êµ (`wandb.Table`) |\n",
        "| **Artifacts** | ë°ì´í„°ì…‹/ëª¨ë¸ ë²„ì €ë‹ ë° ê³„ë³´(lineage) ì¶”ì  |\n",
        "| **Model Registry** | ëª¨ë¸ ë“±ë¡ ë° alias ê´€ë¦¬ (UIì—ì„œ ìˆ˜í–‰) |\n",
        "| **Sweeps** | ë² ì´ì§€ì•ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” + íŠœë‹ íš¨ê³¼ ê²€ì¦ |\n",
        "| **Reports** | í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‹¤í—˜ ë¦¬í¬íŠ¸ ìƒì„± |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5r2TO1ITftG",
        "outputId": "10a9d991-847c-4d10-e2d1-31b238451a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "COCO classes: 80ê°œ\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import glob\n",
        "import csv\n",
        "\n",
        "BASELINE_CONFIG = {\n",
        "    \"model_name\": \"yolov8n-seg\",\n",
        "    \"dataset\": \"coco128-seg\",\n",
        "    \"epochs\": 30,\n",
        "    \"imgsz\": 640,\n",
        "    \"lr0\": 0.01,\n",
        "    \"batch\": 16,\n",
        "    \"num_classes\": 80,\n",
        "}\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
        "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
        "    \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n",
        "    \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "    \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\",\n",
        "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
        "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\",\n",
        "]\n",
        "\n",
        "CLASS_LABELS = {i: name for i, name in enumerate(COCO_CLASSES)}\n",
        "MASK_CLASS_LABELS = {0: \"background\"}\n",
        "MASK_CLASS_LABELS.update({i + 1: name for i, name in enumerate(COCO_CLASSES)})\n",
        "\n",
        "ARTIFACT_NAME = \"yolov8n-seg-coco128\"\n",
        "\n",
        "print(f\"COCO classes: {len(COCO_CLASSES)}ê°œ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY3hsmPiTftG",
        "outputId": "46edda81-5ba9-4450-8985-d2cbf6ba8f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
          ]
        }
      ],
      "source": [
        "# === í—¬í¼ í•¨ìˆ˜ ===\n",
        "\n",
        "def parse_yolo_seg_label(label_path):\n",
        "    \"\"\"YOLO-seg ë¼ë²¨ì—ì„œ class_idì™€ polygonì„ íŒŒì‹±í•œë‹¤.\"\"\"\n",
        "    objects = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return objects\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 7:\n",
        "                continue\n",
        "            cls_id = int(parts[0])\n",
        "            coords = [float(x) for x in parts[1:]]\n",
        "            xs, ys = coords[0::2], coords[1::2]\n",
        "            objects.append({\n",
        "                \"cls_id\": cls_id,\n",
        "                \"polygon\": list(zip(xs, ys)),\n",
        "                \"bbox\": {\"x_min\": min(xs), \"y_min\": min(ys), \"x_max\": max(xs), \"y_max\": max(ys)},\n",
        "            })\n",
        "    return objects\n",
        "\n",
        "\n",
        "def polygons_to_mask(objects, img_w, img_h):\n",
        "    \"\"\"GT ì˜¤ë¸Œì íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ í´ë˜ìŠ¤ë³„ ë§ˆìŠ¤í¬(2D int array)ë¡œ ë³€í™˜í•œë‹¤.\"\"\"\n",
        "    mask = np.zeros((img_h, img_w), dtype=np.int32)\n",
        "    for obj in objects:\n",
        "        pts = [(x * img_w, y * img_h) for x, y in obj[\"polygon\"]]\n",
        "        if len(pts) >= 3:\n",
        "            pil_mask = Image.new(\"L\", (img_w, img_h), 0)\n",
        "            ImageDraw.Draw(pil_mask).polygon(pts, fill=1)\n",
        "            mask[np.array(pil_mask) > 0] = obj[\"cls_id\"] + 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "def pred_to_mask(r, img_w, img_h):\n",
        "    \"\"\"YOLO ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ ë§ˆìŠ¤í¬(2D int array)ë¡œ ë³€í™˜í•œë‹¤.\"\"\"\n",
        "    mask = np.zeros((img_h, img_w), dtype=np.int32)\n",
        "    if r.masks is None:\n",
        "        return mask\n",
        "    for poly_xy, box in zip(r.masks.xy, r.boxes):\n",
        "        pts = [(float(p[0]), float(p[1])) for p in poly_xy]\n",
        "        if len(pts) >= 3:\n",
        "            pil_mask = Image.new(\"L\", (img_w, img_h), 0)\n",
        "            ImageDraw.Draw(pil_mask).polygon(pts, fill=1)\n",
        "            mask[np.array(pil_mask) > 0] = int(box.cls) + 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "def compute_miou(gt_mask, pred_mask):\n",
        "    \"\"\"GT ë§ˆìŠ¤í¬ì™€ ì˜ˆì¸¡ ë§ˆìŠ¤í¬ì˜ mIoUë¥¼ ê³„ì‚°í•œë‹¤.\"\"\"\n",
        "    classes = set(np.unique(gt_mask)) | set(np.unique(pred_mask))\n",
        "    classes.discard(0)\n",
        "    if not classes:\n",
        "        return 0.0\n",
        "    ious = []\n",
        "    for c in classes:\n",
        "        inter = np.logical_and(gt_mask == c, pred_mask == c).sum()\n",
        "        union = np.logical_or(gt_mask == c, pred_mask == c).sum()\n",
        "        if union > 0:\n",
        "            ious.append(inter / union)\n",
        "    return float(np.mean(ious)) if ious else 0.0\n",
        "\n",
        "\n",
        "def build_prediction_table(yolo_model, image_paths):\n",
        "    \"\"\"ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ wandb.Tableë¡œ ìƒì„±í•œë‹¤.\"\"\"\n",
        "    table = wandb.Table(columns=[\n",
        "        \"Detection\", \"Segmentation\", \"Detected Classes\",\n",
        "        \"Num Objects\", \"Avg Confidence\", \"mIoU\",\n",
        "    ])\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = Image.open(img_path)\n",
        "        img_w, img_h = img.size\n",
        "        r = yolo_model(img_path, verbose=False)[0]\n",
        "\n",
        "        # --- Detection column (ì¸í„°ë™í‹°ë¸Œ BBox) ---\n",
        "        box_data, detected_classes, confs = [], set(), []\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "            cls_id, conf = int(box.cls), float(box.conf)\n",
        "            box_data.append({\n",
        "                \"position\": {\"minX\": x1/img_w, \"minY\": y1/img_h, \"maxX\": x2/img_w, \"maxY\": y2/img_h},\n",
        "                \"class_id\": cls_id,\n",
        "                \"scores\": {\"confidence\": conf},\n",
        "                \"box_caption\": f\"{COCO_CLASSES[cls_id]} {conf:.2f}\",\n",
        "            })\n",
        "            detected_classes.add(COCO_CLASSES[cls_id])\n",
        "            confs.append(conf)\n",
        "        det_img = wandb.Image(\n",
        "            img,\n",
        "            boxes={\"predictions\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "        )\n",
        "\n",
        "        # --- Segmentation column (ì¸í„°ë™í‹°ë¸Œ ë§ˆìŠ¤í¬: í´ë˜ìŠ¤ë³„ on/off ê°€ëŠ¥) ---\n",
        "        pred_mask = pred_to_mask(r, img_w, img_h)\n",
        "        seg_img = wandb.Image(\n",
        "            img,\n",
        "            masks={\"predictions\": {\"mask_data\": pred_mask, \"class_labels\": MASK_CLASS_LABELS}},\n",
        "        )\n",
        "\n",
        "        # --- mIoU (GT ë¼ë²¨ ëŒ€ë¹„) ---\n",
        "        label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "        gt_objects = parse_yolo_seg_label(label_path)\n",
        "        gt_mask = polygons_to_mask(gt_objects, img_w, img_h)\n",
        "        miou = compute_miou(gt_mask, pred_mask)\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "        table.add_data(\n",
        "            det_img, seg_img, \", \".join(sorted(detected_classes)),\n",
        "            len(r.boxes), f\"{avg_conf:.2%}\", round(miou, 4),\n",
        "        )\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "def log_training_metrics(results_save_dir):\n",
        "    \"\"\"YOLO í•™ìŠµ ê²°ê³¼ CSVë¥¼ W&Bì— ë¡œê¹…í•œë‹¤.\"\"\"\n",
        "    csv_path = os.path.join(results_save_dir, \"results.csv\")\n",
        "    if not os.path.exists(csv_path):\n",
        "        return\n",
        "    with open(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            row = {k.strip(): v.strip() for k, v in row.items()}\n",
        "            wandb.log({\n",
        "                \"epoch\": int(row[\"epoch\"]),\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]),\n",
        "                \"train/seg_loss\": float(row[\"train/seg_loss\"]),\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]),\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]),\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]),\n",
        "                \"val/seg_loss\": float(row[\"val/seg_loss\"]),\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]),\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]),\n",
        "                \"val/mAP50_box\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"val/mAP50-95_box\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "                \"val/precision_box\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"val/recall_box\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"val/mAP50_mask\": float(row[\"metrics/mAP50(M)\"]),\n",
        "                \"val/mAP50-95_mask\": float(row[\"metrics/mAP50-95(M)\"]),\n",
        "            })\n",
        "\n",
        "\n",
        "print(\"í—¬í¼ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOCIwPE7TftH"
      },
      "source": [
        "## 1. ë°ì´í„°ì…‹ ì¤€ë¹„ + Artifact ë“±ë¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89JKCYqTftH",
        "outputId": "132873f9-2ae6-4a97-807e-821c0d4e2422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING âš ï¸ Dataset 'coco128-seg.yaml' images not found, missing path '/content/datasets/coco128-seg/images/train2017'\n",
            "\u001b[KDownloading https://ultralytics.com/assets/coco128-seg.zip to '/content/datasets/coco128-seg.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.8MB 204.3MB/s 0.0s\n",
            "\u001b[KUnzipping /content/datasets/coco128-seg.zip to /content/datasets/coco128-seg...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 263/263 1.3Kfiles/s 0.2s\n",
            "Dataset download success âœ… (0.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 108.0MB/s 0.0s\n",
            "ë°ì´í„°ì…‹ ê²½ë¡œ: /content/datasets/coco128-seg\n",
            "Train ì´ë¯¸ì§€: 128ì¥\n"
          ]
        }
      ],
      "source": [
        "data_info = check_det_dataset(\"coco128-seg.yaml\")\n",
        "DATASET_DIR = data_info[\"path\"]\n",
        "train_images = glob.glob(f\"{DATASET_DIR}/images/train2017/*.jpg\")\n",
        "print(f\"ë°ì´í„°ì…‹ ê²½ë¡œ: {DATASET_DIR}\")\n",
        "print(f\"Train ì´ë¯¸ì§€: {len(train_images)}ì¥\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ys5_YzzbTftH",
        "outputId": "94a55f80-53b7-4513-b3ae-2e48614afa52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260220_134832-9zxvgzcp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/9zxvgzcp' target=\"_blank\">coco128-seg-data-versioning</a></strong> to <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/9zxvgzcp' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/9zxvgzcp</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/datasets/coco128-seg)... Done. 0.2s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">coco128-seg-data-versioning</strong> at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/9zxvgzcp' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/9zxvgzcp</a><br> View project at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a><br>Synced 5 W&B file(s), 1 media file(s), 43 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260220_134832-9zxvgzcp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë°ì´í„°ì…‹ Artifact + GT ì‹œê°í™” ë¡œê¹… ì™„ë£Œ!\n"
          ]
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"data-versioning\",\n",
        "    name=\"coco128-seg-data-versioning\",\n",
        ")\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    \"coco128-seg\",\n",
        "    type=\"dataset\",\n",
        "    description=\"COCO128-seg dataset (128 images, 80 classes, instance segmentation labels)\",\n",
        "    metadata={\n",
        "        \"num_images\": len(train_images),\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"format\": \"YOLO-seg\",\n",
        "    },\n",
        ")\n",
        "artifact.add_dir(DATASET_DIR)\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# GT BBox + Mask ì‹œê°í™” í…Œì´ë¸”\n",
        "table = wandb.Table(columns=[\"GT Overlay\", \"Num Objects\", \"Classes\"])\n",
        "sample_images = random.sample(train_images, min(20, len(train_images)))\n",
        "\n",
        "for img_path in sample_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "    label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "    gt_objects = parse_yolo_seg_label(label_path)\n",
        "\n",
        "    box_data = []\n",
        "    for obj in gt_objects:\n",
        "        bb = obj[\"bbox\"]\n",
        "        box_data.append({\n",
        "            \"position\": {\"minX\": bb[\"x_min\"], \"minY\": bb[\"y_min\"], \"maxX\": bb[\"x_max\"], \"maxY\": bb[\"y_max\"]},\n",
        "            \"class_id\": obj[\"cls_id\"],\n",
        "            \"box_caption\": COCO_CLASSES[obj[\"cls_id\"]] if obj[\"cls_id\"] < len(COCO_CLASSES) else str(obj[\"cls_id\"]),\n",
        "        })\n",
        "\n",
        "    gt_mask = polygons_to_mask(gt_objects, img_w, img_h)\n",
        "    gt_img = wandb.Image(\n",
        "        img,\n",
        "        boxes={\"ground_truth\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "        masks={\"ground_truth\": {\"mask_data\": gt_mask, \"class_labels\": MASK_CLASS_LABELS}},\n",
        "    )\n",
        "    class_names = list({COCO_CLASSES[o[\"cls_id\"]] for o in gt_objects})\n",
        "    table.add_data(gt_img, len(gt_objects), \", \".join(class_names))\n",
        "\n",
        "wandb.log({\"dataset_preview\": table})\n",
        "wandb.finish()\n",
        "print(\"ë°ì´í„°ì…‹ Artifact + GT ì‹œê°í™” ë¡œê¹… ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP3JTO-lTftH"
      },
      "source": [
        "## 2. Xavier ì´ˆê¸°í™” ëª¨ë¸ ë“±ë¡\n",
        "\n",
        "í•™ìŠµì„ ì‹œì‘í•˜ê¸° ì „, **Xavier ì´ˆê¸°í™”**ë§Œ ì ìš©í•œ ëª¨ë¸ì„ Artifactë¡œ ë“±ë¡í•©ë‹ˆë‹¤.\n",
        "ì´ ëª¨ë¸ì€ ì•„ë¬´ê²ƒë„ í•™ìŠµí•˜ì§€ ì•Šì€ ìƒíƒœì´ë¯€ë¡œ, í•™ìŠµ ì „í›„ì˜ ì„±ëŠ¥ ì°¨ì´ë¥¼ ëª…í™•í•˜ê²Œ ë³´ì—¬ì£¼ëŠ” ê¸°ì¤€ì  ì—­í• ì„ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "q0GLSYCjTftH",
        "outputId": "ecd6e8e8-dcc9-4a41-96c6-9540240f6758"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260220_134852-px6xq9qg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/px6xq9qg' target=\"_blank\">yolov8n-seg-xavier-init</a></strong> to <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/px6xq9qg' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/px6xq9qg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xavier ì´ˆê¸°í™” ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: xavier-init)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n-seg-xavier-init</strong> at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/px6xq9qg' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/px6xq9qg</a><br> View project at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260220_134852-px6xq9qg/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"model-init\",\n",
        "    name=\"yolov8n-seg-xavier-init\",\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128-seg:latest\")\n",
        "\n",
        "init_model = YOLO(\"yolov8n-seg.yaml\")\n",
        "\n",
        "for m in init_model.model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "XAVIER_PT = \"yolov8n-seg-xavier.pt\"\n",
        "torch.save({\"model\": init_model.model}, XAVIER_PT)\n",
        "\n",
        "xavier_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg with Xavier initialization (no training)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"initialization\": \"xavier_uniform\",\n",
        "        \"trained\": False,\n",
        "        \"best_mAP50\": 0.0,\n",
        "        \"best_mAP50_mask\": 0.0,\n",
        "    },\n",
        ")\n",
        "xavier_artifact.add_file(XAVIER_PT, name=\"best.pt\")\n",
        "run.log_artifact(xavier_artifact, aliases=[\"xavier-init\"])\n",
        "\n",
        "# Model Registry ë“±ë¡ â€” UIì—ì„œ ì§ì ‘ ìˆ˜í–‰í•©ë‹ˆë‹¤\n",
        "# run.link_artifact(\n",
        "#     xavier_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"xavier-init\"],\n",
        "# )\n",
        "\n",
        "print(\"Xavier ì´ˆê¸°í™” ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: xavier-init)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config={**BASELINE_CONFIG, \"initialization\": \"xavier_uniform\", \"pretrained\": False},\n",
        "    job_type=\"training\",\n",
        "    name=\"xavier-trained-yolov8n-seg\",\n",
        "    tags=[\"xavier\", \"from-scratch\"],\n",
        ")\n",
        "\n",
        "xavier_model = YOLO(\"yolov8n-seg-xavier.pt\")\n",
        "\n",
        "xavier_results = xavier_model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=BASELINE_CONFIG[\"imgsz\"],\n",
        "    lr0=BASELINE_CONFIG[\"lr0\"],\n",
        "    batch=BASELINE_CONFIG[\"batch\"],\n",
        "    project=\"runs/segment\",\n",
        "    name=\"xavier_trained\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "log_training_metrics(xavier_results.save_dir)\n",
        "\n",
        "XAVIER_BEST_PT = os.path.join(xavier_results.save_dir, \"weights/best.pt\")\n",
        "xavier_metrics = xavier_results.results_dict\n",
        "xavier_mAP50_box = xavier_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "xavier_mAP50_mask = xavier_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "xavier_best_model = YOLO(XAVIER_BEST_PT)\n",
        "eval_images_xavier = random.sample(train_images, min(30, len(train_images)))\n",
        "pred_table_xavier = build_prediction_table(xavier_best_model, eval_images_xavier)\n",
        "wandb.log({\"prediction_table\": pred_table_xavier})\n",
        "\n",
        "xavier_trained_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg trained from Xavier init (from scratch) on COCO128-seg\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"initialization\": \"xavier_uniform\",\n",
        "        \"pretrained\": False,\n",
        "        \"best_mAP50\": xavier_mAP50_box,\n",
        "        \"best_mAP50_mask\": xavier_mAP50_mask,\n",
        "        \"sweep_tuned\": False,\n",
        "    },\n",
        ")\n",
        "xavier_trained_artifact.add_file(XAVIER_BEST_PT, name=\"best.pt\")\n",
        "run.log_artifact(xavier_trained_artifact, aliases=[\"xavier-trained\"])\n",
        "\n",
        "print(f\"\\nXavier ì´ˆê¸°í™” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(f\"  mAP50 (Box):  {xavier_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {xavier_mAP50_mask:.4f}\")\n",
        "print(\"Xavier í•™ìŠµ ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: xavier-trained)\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_b7icccTTmX1",
        "outputId": "92329bd3-a3d1-4467-e38f-5c94af07a6f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.25.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260220_135749-40n2kj4y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/40n2kj4y' target=\"_blank\">xavier-trained-yolov8n-seg</a></strong> to <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/40n2kj4y' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/40n2kj4y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco128-seg.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg-xavier.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=xavier_trained, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/segment, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/runs/segment/xavier_trained, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1150432  ultralytics.nn.modules.head.Segment          [80, 32, 64, 16, None, [64, 128, 256]]\n",
            "YOLOv8n-seg summary: 152 layers, 3,409,968 parameters, 3,409,952 gradients, 12.1 GFLOPs\n",
            "\n",
            "Transferred 417/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1121.6Â±479.0 MB/s, size: 50.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco128-seg/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 26.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 432.2Â±153.2 MB/s, size: 52.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco128-seg/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 5.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "Plotting labels to /content/runs/segment/runs/segment/xavier_trained/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/runs/segment/xavier_trained\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       1/30      3.05G      3.483      14.09       9482       4.35          0        181        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.1it/s 7.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       2/30      3.07G      3.608      16.03  1.041e+04      4.395          0        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.2it/s 3.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       3/30      3.09G      3.551      12.92       9874      4.364          0        195        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.1it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       4/30      3.09G      3.536      15.38  1.003e+04      4.387          0        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.9it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       5/30      3.09G      3.511      11.84       9882      4.369          0        240        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.0it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       6/30      3.09G      3.612      13.96  1.008e+04       4.37          0        260        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.9it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.8s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       7/30      3.09G      3.553      14.68       9363      4.354          0        289        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.1it/s 3.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.8s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       8/30      3.09G      3.565      12.75       8848      4.337          0        197        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.1it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.8s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K       9/30      3.09G      3.554      15.36       9547      4.356          0        183        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.1it/s 3.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      10/30      3.09G      3.648      12.67       9136      4.323          0        185        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.4it/s 3.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      11/30      3.09G      3.592      12.05       8927      4.309          0        267        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.4it/s 3.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      12/30      3.09G      3.683      10.95       9708       4.31          0        183        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      13/30      3.09G      3.713      8.596       8614      4.252          0        254        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      14/30      3.09G      3.582      11.17       9096      4.298          0        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.6it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      15/30      3.09G      3.643      10.36       8359      4.288          0        255        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      16/30      3.09G      3.639      9.413       9291      4.278          0        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      17/30      3.09G      3.562      10.42       8621      4.282          0        192        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      18/30      3.09G      3.672      8.383       8058      4.232          0        214        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      19/30      3.09G      3.606      6.899       9012      4.215          0        173        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      20/30      3.09G      3.655      8.714       8629      4.224          0        189        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.6it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      21/30      3.09G      3.523      11.75  1.536e+04      4.262          0        126        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 1.4it/s 5.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      22/30      3.09G      3.491      9.549  1.647e+04      4.278          0         78        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      23/30      3.09G       3.44      9.126  1.654e+04      4.347          0         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.8it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.8s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      24/30      3.09G      3.431      11.41  1.622e+04      4.368          0        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      25/30      3.09G        3.5      12.14   1.55e+04      4.253          0        129        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      26/30      3.09G      3.544      11.08   1.64e+04       4.32          0        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.3it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      27/30      3.09G       3.49      9.206   1.61e+04      4.301          0         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 10.0s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      28/30      3.09G      3.541       7.36  1.588e+04      4.257          0         65        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      29/30      3.09G      3.494      9.236  1.582e+04      4.255          0        142        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss   sem_loss  Instances       Size\n",
            "\u001b[K      30/30      3.09G       3.48      11.11  1.615e+04      4.261          0        105        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.3it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.5s/it 9.9s\n",
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "\n",
            "30 epochs completed in 0.115 hours.\n",
            "Optimizer stripped from /content/runs/segment/runs/segment/xavier_trained/weights/last.pt, 7.1MB\n",
            "Optimizer stripped from /content/runs/segment/runs/segment/xavier_trained/weights/best.pt, 7.1MB\n",
            "\n",
            "Validating /content/runs/segment/runs/segment/xavier_trained/weights/best.pt...\n",
            "Ultralytics 8.4.14 ğŸš€ Python-3.12.12 torch-2.10.0+cu128 CUDA:0 (Tesla T4, 14913MiB)\n",
            "YOLOv8n-seg summary (fused): 86 layers, 3,404,320 parameters, 0 gradients, 12.0 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 25% â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1/4 8.8s/it 2.6s<26.5s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-54 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 796, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 326, in box_label\n",
            "    ) if multi_points else self.draw.rectangle(box, width=self.lw, outline=color)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/ImageDraw.py\", line 398, in rectangle\n",
            "    self.draw.draw_rectangle(xy, ink, 0, width)\n",
            "ValueError: x1 must be greater than or equal to x0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 50% â”â”â”â”â”â”â”€â”€â”€â”€â”€â”€ 2/4 5.6s/it 5.7s<11.2s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-56 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 796, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 326, in box_label\n",
            "    ) if multi_points else self.draw.rectangle(box, width=self.lw, outline=color)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/ImageDraw.py\", line 398, in rectangle\n",
            "    self.draw.draw_rectangle(xy, ink, 0, width)\n",
            "ValueError: x1 must be greater than or equal to x0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 2.9s/it 11.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-58 (plot_images):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 796, in plot_images\n",
            "    annotator.box_label(box, label, color=color)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/utils/plotting.py\", line 326, in box_label\n",
            "    ) if multi_points else self.draw.rectangle(box, width=self.lw, outline=color)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/PIL/ImageDraw.py\", line 398, in rectangle\n",
            "    self.draw.draw_rectangle(xy, ink, 0, width)\n",
            "ValueError: x1 must be greater than or equal to x0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        128        929          0          0          0          0          0          0          0          0\n",
            "                person         61        254          0          0          0          0          0          0          0          0\n",
            "               bicycle          3          6          0          0          0          0          0          0          0          0\n",
            "                   car         12         46          0          0          0          0          0          0          0          0\n",
            "            motorcycle          4          5          0          0          0          0          0          0          0          0\n",
            "              airplane          5          6          0          0          0          0          0          0          0          0\n",
            "                   bus          5          7          0          0          0          0          0          0          0          0\n",
            "                 train          3          3          0          0          0          0          0          0          0          0\n",
            "                 truck          5         12          0          0          0          0          0          0          0          0\n",
            "                  boat          2          6          0          0          0          0          0          0          0          0\n",
            "         traffic light          4         14          0          0          0          0          0          0          0          0\n",
            "             stop sign          2          2          0          0          0          0          0          0          0          0\n",
            "                 bench          5          9          0          0          0          0          0          0          0          0\n",
            "                  bird          2         16          0          0          0          0          0          0          0          0\n",
            "                   cat          4          4          0          0          0          0          0          0          0          0\n",
            "                   dog          9          9          0          0          0          0          0          0          0          0\n",
            "                 horse          1          2          0          0          0          0          0          0          0          0\n",
            "              elephant          4         17          0          0          0          0          0          0          0          0\n",
            "                  bear          1          1          0          0          0          0          0          0          0          0\n",
            "                 zebra          2          4          0          0          0          0          0          0          0          0\n",
            "               giraffe          4          9          0          0          0          0          0          0          0          0\n",
            "              backpack          4          6          0          0          0          0          0          0          0          0\n",
            "              umbrella          4         18          0          0          0          0          0          0          0          0\n",
            "               handbag          9         19          0          0          0          0          0          0          0          0\n",
            "                   tie          6          7          0          0          0          0          0          0          0          0\n",
            "              suitcase          2          4          0          0          0          0          0          0          0          0\n",
            "               frisbee          5          5          0          0          0          0          0          0          0          0\n",
            "                  skis          1          1          0          0          0          0          0          0          0          0\n",
            "             snowboard          2          7          0          0          0          0          0          0          0          0\n",
            "           sports ball          6          6          0          0          0          0          0          0          0          0\n",
            "                  kite          2         10          0          0          0          0          0          0          0          0\n",
            "          baseball bat          4          4          0          0          0          0          0          0          0          0\n",
            "        baseball glove          4          7          0          0          0          0          0          0          0          0\n",
            "            skateboard          3          5          0          0          0          0          0          0          0          0\n",
            "         tennis racket          5          7          0          0          0          0          0          0          0          0\n",
            "                bottle          6         18          0          0          0          0          0          0          0          0\n",
            "            wine glass          5         16          0          0          0          0          0          0          0          0\n",
            "                   cup         10         36          0          0          0          0          0          0          0          0\n",
            "                  fork          6          6          0          0          0          0          0          0          0          0\n",
            "                 knife          7         16          0          0          0          0          0          0          0          0\n",
            "                 spoon          5         22          0          0          0          0          0          0          0          0\n",
            "                  bowl          9         28          0          0          0          0          0          0          0          0\n",
            "                banana          1          1          0          0          0          0          0          0          0          0\n",
            "              sandwich          2          2          0          0          0          0          0          0          0          0\n",
            "                orange          1          4          0          0          0          0          0          0          0          0\n",
            "              broccoli          4         11          0          0          0          0          0          0          0          0\n",
            "                carrot          3         24          0          0          0          0          0          0          0          0\n",
            "               hot dog          1          2          0          0          0          0          0          0          0          0\n",
            "                 pizza          5          5          0          0          0          0          0          0          0          0\n",
            "                 donut          2         14          0          0          0          0          0          0          0          0\n",
            "                  cake          4          4          0          0          0          0          0          0          0          0\n",
            "                 chair          9         35          0          0          0          0          0          0          0          0\n",
            "                 couch          5          6          0          0          0          0          0          0          0          0\n",
            "          potted plant          9         14          0          0          0          0          0          0          0          0\n",
            "                   bed          3          3          0          0          0          0          0          0          0          0\n",
            "          dining table         10         13          0          0          0          0          0          0          0          0\n",
            "                toilet          2          2          0          0          0          0          0          0          0          0\n",
            "                    tv          2          2          0          0          0          0          0          0          0          0\n",
            "                laptop          2          3          0          0          0          0          0          0          0          0\n",
            "                 mouse          2          2          0          0          0          0          0          0          0          0\n",
            "                remote          5          8          0          0          0          0          0          0          0          0\n",
            "            cell phone          5          8          0          0          0          0          0          0          0          0\n",
            "             microwave          3          3          0          0          0          0          0          0          0          0\n",
            "                  oven          5          5          0          0          0          0          0          0          0          0\n",
            "                  sink          4          6          0          0          0          0          0          0          0          0\n",
            "          refrigerator          5          5          0          0          0          0          0          0          0          0\n",
            "                  book          6         29          0          0          0          0          0          0          0          0\n",
            "                 clock          8          9          0          0          0          0          0          0          0          0\n",
            "                  vase          2          2          0          0          0          0          0          0          0          0\n",
            "              scissors          1          1          0          0          0          0          0          0          0          0\n",
            "            teddy bear          6         21          0          0          0          0          0          0          0          0\n",
            "            toothbrush          2          5          0          0          0          0          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 2.6ms inference, 0.0ms loss, 72.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/runs/segment/xavier_trained\u001b[0m\n",
            "\n",
            "Xavier ì´ˆê¸°í™” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
            "  mAP50 (Box):  0.0000\n",
            "  mAP50 (Mask): 0.0000\n",
            "Xavier í•™ìŠµ ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: xavier-trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/box_loss</td><td>â–‚â–…â–„â–„â–ƒâ–†â–„â–„â–„â–†â–…â–‡â–ˆâ–…â–†â–†â–„â–‡â–…â–‡â–ƒâ–‚â–â–â–ƒâ–„â–‚â–„â–ƒâ–‚</td></tr><tr><td>train/cls_loss</td><td>â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆ</td></tr><tr><td>train/dfl_loss</td><td>â–†â–ˆâ–‡â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–‚â–„â–„â–ƒâ–„â–‚â–â–â–ƒâ–ƒâ–†â–‡â–‚â–…â–„â–ƒâ–ƒâ–ƒ</td></tr><tr><td>train/seg_loss</td><td>â–‡â–ˆâ–†â–ˆâ–…â–†â–‡â–…â–‡â–…â–…â–„â–‚â–„â–„â–ƒâ–„â–‚â–â–‚â–…â–ƒâ–ƒâ–„â–…â–„â–ƒâ–â–ƒâ–„</td></tr><tr><td>val/box_loss</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>val/dfl_loss</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–…â–†â–‡â–ˆâ–ˆ</td></tr><tr><td>val/mAP50-95_box</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/mAP50-95_mask</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/mAP50_box</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train/box_loss</td><td>3.47987</td></tr><tr><td>train/cls_loss</td><td>16151.8</td></tr><tr><td>train/dfl_loss</td><td>4.26137</td></tr><tr><td>train/seg_loss</td><td>11.1103</td></tr><tr><td>val/box_loss</td><td>3.44457</td></tr><tr><td>val/cls_loss</td><td>inf</td></tr><tr><td>val/dfl_loss</td><td>4.26613</td></tr><tr><td>val/mAP50-95_box</td><td>0</td></tr><tr><td>val/mAP50-95_mask</td><td>0</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">xavier-trained-yolov8n-seg</strong> at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo/runs/40n2kj4y' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo/runs/40n2kj4y</a><br> View project at: <a href='https://wandb.ai/wandb-korea/e2e-cv-demo' target=\"_blank\">https://wandb.ai/wandb-korea/e2e-cv-demo</a><br>Synced 5 W&B file(s), 1 media file(s), 66 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260220_135749-40n2kj4y/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJxjqjpTTftH"
      },
      "source": [
        "## 3. Baseline í•™ìŠµ â€” ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "\n",
        "ê¸°ë³¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°(`lr0=0.01`, `batch=16`)ë¡œ YOLOv8n-segë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "ì´ ê²°ê³¼ë¥¼ ê¸°ì¤€ì (baseline)ìœ¼ë¡œ ì‚¼ì•„, Sweepì„ í†µí•´ ì–¼ë§ˆë‚˜ ê°œì„ ë˜ëŠ”ì§€ ë¹„êµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_Uu5SGsTftI"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"training\",\n",
        "    name=\"baseline-yolov8n-seg\",\n",
        "    tags=[\"baseline\"],\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128-seg:latest\")\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=BASELINE_CONFIG[\"imgsz\"],\n",
        "    lr0=BASELINE_CONFIG[\"lr0\"],\n",
        "    batch=BASELINE_CONFIG[\"batch\"],\n",
        "    project=\"runs/segment\",\n",
        "    name=\"baseline\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "log_training_metrics(results.save_dir)\n",
        "\n",
        "BASELINE_BEST_PT = os.path.join(results.save_dir, \"weights/best.pt\")\n",
        "baseline_metrics = results.results_dict\n",
        "baseline_mAP50_box = baseline_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "baseline_mAP50_mask = baseline_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"Baseline í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(f\"  mAP50 (Box):  {baseline_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {baseline_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkp2wcRKTftI"
      },
      "outputs": [],
      "source": [
        "best_model = YOLO(BASELINE_BEST_PT)\n",
        "eval_images = random.sample(train_images, min(30, len(train_images)))\n",
        "\n",
        "pred_table = build_prediction_table(best_model, eval_images)\n",
        "wandb.log({\"prediction_table\": pred_table})\n",
        "print(f\"Prediction Table ({len(eval_images)}ì¥) ë¡œê¹… ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m74bNvkJTftI"
      },
      "outputs": [],
      "source": [
        "baseline_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg baseline on COCO128-seg (default hyperparameters)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": baseline_mAP50_box,\n",
        "        \"best_mAP50_mask\": baseline_mAP50_mask,\n",
        "        \"sweep_tuned\": False,\n",
        "    },\n",
        ")\n",
        "baseline_artifact.add_file(BASELINE_BEST_PT, name=\"best.pt\")\n",
        "run.log_artifact(baseline_artifact, aliases=[\"baseline\"])\n",
        "\n",
        "# Model Registry ë“±ë¡ â€” UIì—ì„œ ì§ì ‘ ìˆ˜í–‰í•©ë‹ˆë‹¤\n",
        "# run.link_artifact(\n",
        "#     baseline_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"baseline\"],\n",
        "# )\n",
        "\n",
        "print(\"Baseline ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: baseline)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUYEBym2TftI"
      },
      "source": [
        "## 4. W&B Sweep â€” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
        "\n",
        "W&B Sweepsì˜ **ë² ì´ì§€ì•ˆ ìµœì í™”**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
        "ì—¬ëŸ¬ ë²ˆì˜ Sweep runì„ í†µí•´ ìµœì  ì¡°í•©ì„ ì°¾ì•„ê°€ëŠ” ê³¼ì •ì„ ê´€ì°°í•˜ì„¸ìš”.\n",
        "\n",
        "**íƒìƒ‰ íŒŒë¼ë¯¸í„°:**\n",
        "- `lr0`: ì´ˆê¸° í•™ìŠµë¥  (0.001 ~ 0.02)\n",
        "- `lrf`: ìµœì¢… í•™ìŠµë¥  ë¹„ìœ¨ (0.01 ~ 0.2)\n",
        "- `momentum`: SGD ëª¨ë©˜í…€ (0.85 ~ 0.98)\n",
        "- `weight_decay`: ê°€ì¤‘ì¹˜ ê°ì‡  (0.0001 ~ 0.001)\n",
        "- `warmup_epochs`: ì›œì—… ì—í¬í¬ ìˆ˜ (1, 2, 3)\n",
        "- `mosaic`: ëª¨ìì´í¬ ì¦ê°• ë¹„ìœ¨ (0.5 ~ 1.0)\n",
        "\n",
        "**ìµœì í™” ëª©í‘œ:** `val/mAP50_box` ìµœëŒ€í™”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZDYESWxTftI"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val/mAP50_box\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"lr0\": {\"min\": 0.001, \"max\": 0.02},\n",
        "        \"lrf\": {\"min\": 0.01, \"max\": 0.2},\n",
        "        \"momentum\": {\"min\": 0.85, \"max\": 0.98},\n",
        "        \"weight_decay\": {\"min\": 0.0001, \"max\": 0.001},\n",
        "        \"warmup_epochs\": {\"values\": [1, 2, 3]},\n",
        "        \"mosaic\": {\"min\": 0.5, \"max\": 1.0},\n",
        "    },\n",
        "}\n",
        "\n",
        "SWEEP_EPOCHS = 10\n",
        "\n",
        "\n",
        "def sweep_train():\n",
        "    run = wandb.init()\n",
        "    cfg = wandb.config\n",
        "\n",
        "    sweep_model = YOLO(\"yolov8n-seg.pt\")\n",
        "    sweep_results = sweep_model.train(\n",
        "        data=\"coco128-seg.yaml\",\n",
        "        epochs=SWEEP_EPOCHS,\n",
        "        imgsz=640,\n",
        "        lr0=cfg.lr0,\n",
        "        lrf=cfg.lrf,\n",
        "        momentum=cfg.momentum,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "        warmup_epochs=cfg.warmup_epochs,\n",
        "        mosaic=cfg.mosaic,\n",
        "        batch=16,\n",
        "        project=\"runs/segment_sweep\",\n",
        "        name=f\"sweep_{run.id}\",\n",
        "        exist_ok=True,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    metrics = sweep_results.results_dict\n",
        "    wandb.log({\n",
        "        \"val/mAP50_box\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "        \"val/mAP50-95_box\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        \"val/precision_box\": metrics.get(\"metrics/precision(B)\", 0),\n",
        "        \"val/recall_box\": metrics.get(\"metrics/recall(B)\", 0),\n",
        "        \"val/mAP50_mask\": metrics.get(\"metrics/mAP50(M)\", 0),\n",
        "        \"val/mAP50-95_mask\": metrics.get(\"metrics/mAP50-95(M)\", 0),\n",
        "    })\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=10)\n",
        "print(\"Sweep ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXwHmyC9TftI"
      },
      "source": [
        "## 5. Sweep ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ Full Training\n",
        "\n",
        "Sweepì—ì„œ ì°¾ì€ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ full epoch í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "Baselineê³¼ ë¹„êµí•˜ì—¬ Sweepì˜ íš¨ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHM7NdOxTftI"
      },
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "sweep = api.sweep(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{sweep_id}\")\n",
        "best_run = sweep.best_run()\n",
        "best_config = best_run.config\n",
        "\n",
        "print(\"Sweep ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"  Best mAP50 (Box): {best_run.summary.get('val/mAP50_box', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEOnQsYETftI"
      },
      "outputs": [],
      "source": [
        "tuned_config = {**BASELINE_CONFIG, **best_config}\n",
        "tuned_config[\"sweep_tuned\"] = True\n",
        "tuned_config[\"sweep_id\"] = sweep_id\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=tuned_config,\n",
        "    job_type=\"training\",\n",
        "    name=\"tuned-yolov8n-seg\",\n",
        "    tags=[\"sweep-tuned\"],\n",
        ")\n",
        "\n",
        "tuned_model = YOLO(\"yolov8n-seg.pt\")\n",
        "tuned_results = tuned_model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=640,\n",
        "    lr0=best_config.get(\"lr0\", 0.01),\n",
        "    lrf=best_config.get(\"lrf\", 0.01),\n",
        "    momentum=best_config.get(\"momentum\", 0.937),\n",
        "    weight_decay=best_config.get(\"weight_decay\", 0.0005),\n",
        "    warmup_epochs=best_config.get(\"warmup_epochs\", 3),\n",
        "    mosaic=best_config.get(\"mosaic\", 1.0),\n",
        "    batch=16,\n",
        "    project=\"runs/segment\",\n",
        "    name=\"tuned\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "log_training_metrics(tuned_results.save_dir)\n",
        "\n",
        "TUNED_BEST_PT = os.path.join(tuned_results.save_dir, \"weights/best.pt\")\n",
        "tuned_metrics = tuned_results.results_dict\n",
        "tuned_mAP50_box = tuned_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "tuned_mAP50_mask = tuned_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"Tuned í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(f\"  mAP50 (Box):  {tuned_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {tuned_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW27-ZwPTftI"
      },
      "outputs": [],
      "source": [
        "tuned_best_model = YOLO(TUNED_BEST_PT)\n",
        "eval_images_tuned = random.sample(train_images, min(30, len(train_images)))\n",
        "\n",
        "pred_table_tuned = build_prediction_table(tuned_best_model, eval_images_tuned)\n",
        "wandb.log({\"prediction_table\": pred_table_tuned})\n",
        "print(f\"Tuned Prediction Table ({len(eval_images_tuned)}ì¥) ë¡œê¹… ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLYpbgCeTftI"
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Baseline vs Sweep-Tuned ë¹„êµ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "box_diff = tuned_mAP50_box - baseline_mAP50_box\n",
        "mask_diff = tuned_mAP50_mask - baseline_mAP50_mask\n",
        "\n",
        "print(f\"{'Metric':<20} {'Baseline':>10} {'Tuned':>10} {'Diff':>10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'mAP50 (Box)':<20} {baseline_mAP50_box:>10.4f} {tuned_mAP50_box:>10.4f} {box_diff:>+10.4f}\")\n",
        "print(f\"{'mAP50 (Mask)':<20} {baseline_mAP50_mask:>10.4f} {tuned_mAP50_mask:>10.4f} {mask_diff:>+10.4f}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"comparison/baseline_mAP50_box\": baseline_mAP50_box,\n",
        "    \"comparison/tuned_mAP50_box\": tuned_mAP50_box,\n",
        "    \"comparison/improvement_mAP50_box\": box_diff,\n",
        "    \"comparison/baseline_mAP50_mask\": baseline_mAP50_mask,\n",
        "    \"comparison/tuned_mAP50_mask\": tuned_mAP50_mask,\n",
        "    \"comparison/improvement_mAP50_mask\": mask_diff,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSOha5NETftI"
      },
      "outputs": [],
      "source": [
        "final_mAP50 = max(tuned_mAP50_box, baseline_mAP50_box)\n",
        "final_mAP50_mask = max(tuned_mAP50_mask, baseline_mAP50_mask)\n",
        "final_pt = TUNED_BEST_PT if tuned_mAP50_box >= baseline_mAP50_box else BASELINE_BEST_PT\n",
        "is_tuned_better = tuned_mAP50_box >= baseline_mAP50_box\n",
        "\n",
        "print(f\"ìµœì¢… ëª¨ë¸: {'Tuned' if is_tuned_better else 'Baseline'} (mAP50 Box: {final_mAP50:.4f})\")\n",
        "\n",
        "model_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=f\"YOLOv8n-seg {'sweep-tuned' if is_tuned_better else 'baseline'} on COCO128-seg\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": final_mAP50,\n",
        "        \"best_mAP50_mask\": final_mAP50_mask,\n",
        "        \"sweep_tuned\": is_tuned_better,\n",
        "    },\n",
        ")\n",
        "model_artifact.add_file(final_pt, name=\"best.pt\")\n",
        "run.log_artifact(model_artifact, aliases=[\"latest\"])\n",
        "\n",
        "# Model Registry ë“±ë¡ â€” UIì—ì„œ ì§ì ‘ ìˆ˜í–‰í•©ë‹ˆë‹¤\n",
        "# run.link_artifact(\n",
        "#     model_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"staging\"],\n",
        "# )\n",
        "\n",
        "print(\"ìµœì¢… ëª¨ë¸ Artifact ë“±ë¡ ì™„ë£Œ! (alias: latest)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUe2HKLVTftI"
      },
      "source": [
        "## 6. W&B Report ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r64-pf_8TftI"
      },
      "outputs": [],
      "source": [
        "import wandb_workspaces.reports.v2 as wr\n",
        "\n",
        "report = wr.Report(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    title=\"Unified Vision â€” YOLOv8n-seg ì‹¤í—˜ ê²°ê³¼ ë¦¬í¬íŠ¸\",\n",
        "    description=\"YOLOv8n-seg COCO128 í•™ìŠµ + Sweep í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼\",\n",
        ")\n",
        "\n",
        "report.blocks = [\n",
        "    wr.TableOfContents(),\n",
        "\n",
        "    wr.H1(\"1. ì‹¤í—˜ ê°œìš”\"),\n",
        "    wr.P(\n",
        "        \"COCO128-seg ë°ì´í„°ì…‹ì— ëŒ€í•œ YOLOv8n-seg í†µí•© ë¹„ì „ ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤. \"\n",
        "        \"í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ Classification, Detection, Segmentationì„ ëª¨ë‘ ìˆ˜í–‰í•©ë‹ˆë‹¤. \"\n",
        "        \"W&Bì˜ Experiment Tracking, Artifacts, Sweeps, Model Registry, Media Logging ê¸°ëŠ¥ì„ í™œìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"2. Baseline í•™ìŠµ ê²°ê³¼\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)],\n",
        "        panels=[\n",
        "            wr.LinePlot(title=\"Box Loss (Train)\", x=\"epoch\", y=[\"train/box_loss\"]),\n",
        "            wr.LinePlot(title=\"Seg Loss (Train)\", x=\"epoch\", y=[\"train/seg_loss\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Box)\", x=\"epoch\", y=[\"val/mAP50_box\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Mask)\", x=\"epoch\", y=[\"val/mAP50_mask\"]),\n",
        "            wr.LinePlot(title=\"Precision (Box)\", x=\"epoch\", y=[\"val/precision_box\"]),\n",
        "            wr.LinePlot(title=\"Recall (Box)\", x=\"epoch\", y=[\"val/recall_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"3. Sweep ë¶„ì„\"),\n",
        "    wr.P(\"Bayesian ìµœì í™”ë¥¼ í†µí•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê²°ê³¼:\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)],\n",
        "        panels=[\n",
        "            wr.ParallelCoordinatesPlot(\n",
        "                columns=[\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lr0\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lrf\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::momentum\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::weight_decay\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::mosaic\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"val/mAP50_box\"),\n",
        "                ],\n",
        "            ),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Box)\", metric=\"val/mAP50_box\"),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Mask)\", metric=\"val/mAP50_mask\"),\n",
        "            wr.BarPlot(title=\"mAP@0.5 by Run\", metrics=[\"val/mAP50_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"4. Baseline vs Sweep-Tuned ë¹„êµ\"),\n",
        "    wr.P(\n",
        "        f\"Baseline mAP50 (Box): {baseline_mAP50_box:.4f} â†’ \"\n",
        "        f\"Tuned mAP50 (Box): {tuned_mAP50_box:.4f} \"\n",
        "        f\"(ì°¨ì´: {box_diff:+.4f})\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"5. ë‹¤ìŒ ë‹¨ê³„\"),\n",
        "    wr.P(\n",
        "        \"ìµœì  ëª¨ë¸ì„ Model Registryì˜ 'production' aliasë¡œ ìŠ¹ê²©í•˜ì—¬ \"\n",
        "        \"Automation â†’ GitHub Actions â†’ Streamlit ë°°í¬ íŒŒì´í”„ë¼ì¸ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "report.save()\n",
        "print(f\"Report ìƒì„± ì™„ë£Œ! URL: {report.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mMFmaDITftJ"
      },
      "source": [
        "## 7. Production ìŠ¹ê²© (Automation íŠ¸ë¦¬ê±°)\n",
        "\n",
        "ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ Model Registryì—ì„œ ìµœì‹  ëª¨ë¸ì„ `production` aliasë¡œ ìŠ¹ê²©í•©ë‹ˆë‹¤.\n",
        "\n",
        "W&B Automationì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´:\n",
        "1. `production` alias ì¶”ê°€ ì´ë²¤íŠ¸ ë°œìƒ\n",
        "2. Webhook â†’ GitHub `repository_dispatch` íŠ¸ë¦¬ê±°\n",
        "3. GitHub Actionsê°€ `deployment.json` ì—…ë°ì´íŠ¸ â†’ git push\n",
        "4. Streamlit Cloud ì•±ì´ ìƒˆ ëª¨ë¸ë¡œ ìë™ ë°°í¬\n",
        "\n",
        "**ì°¸ê³ **: W&B UIì—ì„œ ìˆ˜ë™ìœ¼ë¡œ `production` aliasë¥¼ ì¶”ê°€í•´ë„ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmq3n-JKTftJ"
      },
      "outputs": [],
      "source": [
        "# api = wandb.Api()\n",
        "# artifact_path = f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{ARTIFACT_NAME}:latest\"\n",
        "#\n",
        "# try:\n",
        "#     art = api.artifact(artifact_path)\n",
        "#     art.aliases.append(\"production\")\n",
        "#     art.save()\n",
        "#     print(f\"'{artifact_path}'ì— 'production' alias ì¶”ê°€ ì™„ë£Œ!\")\n",
        "#     print(\"W&B Automationì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ë°°í¬ íŒŒì´í”„ë¼ì¸ì´ ìë™ìœ¼ë¡œ íŠ¸ë¦¬ê±°ë©ë‹ˆë‹¤.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Production ìŠ¹ê²© ì‹¤íŒ¨: {e}\")\n",
        "#     print(\"W&B UIì—ì„œ ìˆ˜ë™ìœ¼ë¡œ 'production' aliasë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IpdZv_zTftJ"
      },
      "outputs": [],
      "source": [
        "wandb.finish()\n",
        "print(\"ëª¨ë“  W&B ë¦¬ì†ŒìŠ¤ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ëª¨ ì™„ë£Œ!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}