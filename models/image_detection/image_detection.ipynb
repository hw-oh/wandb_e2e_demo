{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hw-oh/wandb_e2e_demo/blob/main/models/image_detection/image_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q wandb ultralytics wandb-workspaces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import wandb\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "WANDB_API_KEY = userdata.get(\"WANDB_API_KEY\")\n",
        "WANDB_ENTITY = userdata.get(\"WANDB_ENTITY\")\n",
        "WANDB_PROJECT = userdata.get(\"WANDB_PROJECT\")\n",
        "WANDB_REGISTRY_NAME = userdata.get(\"WANDB_REGISTRY_NAME\")\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "print(f\"Entity: {WANDB_ENTITY}\")\n",
        "print(f\"Project: {WANDB_PROJECT}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Object Detection Demo — W&B 전체 기능 체험\n",
        "\n",
        "## 개요\n",
        "\n",
        "이 노트북은 **COCO128** 데이터셋과 **YOLOv8n (nano)** 모델을 사용하여\n",
        "객체 탐지(Object Detection)를 수행하면서, W&B의 핵심 기능을 전부 체험합니다.\n",
        "\n",
        "## 다루는 W&B 기능\n",
        "\n",
        "| 기능 | 설명 |\n",
        "|------|------|\n",
        "| **Experiment Tracking** | 학습 메트릭 실시간 추적 (`wandb.init`, `wandb.log`, `wandb.config`) |\n",
        "| **Media Logging** | BBox 오버레이 시각화 (`wandb.Image` + `boxes` 파라미터) |\n",
        "| **Tables** | 데이터셋 미리보기 및 예측 결과 비교 (`wandb.Table`) |\n",
        "| **Artifacts** | 데이터셋/모델 버저닝 및 계보(lineage) 추적 |\n",
        "| **Model Registry** | 모델 등록 및 alias 관리 (staging) |\n",
        "| **Sweeps** | 베이지안 하이퍼파라미터 최적화 |\n",
        "| **Reports** | 프로그래밍 방식 실험 리포트 생성 |\n",
        "\n",
        "## 데이터셋\n",
        "- **COCO128**: COCO 데이터셋의 소형 서브셋 (128장, 80 classes)\n",
        "- Ultralytics 내장 — `model.train()` 시 자동 다운로드\n",
        "- 빠른 데모에 최적\n",
        "\n",
        "## 모델\n",
        "- **YOLOv8n** (nano) — Ultralytics pretrained on COCO\n",
        "- ~3.2M 파라미터, ~6MB 모델 파일\n",
        "- Colab T4에서 빠른 학습, Streamlit Cloud(CPU)에서 빠른 추론"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import glob\n",
        "import yaml\n",
        "import time\n",
        "\n",
        "CONFIG = {\n",
        "    \"model_name\": \"yolov8n\",\n",
        "    \"dataset\": \"coco128\",\n",
        "    \"epochs\": 30,\n",
        "    \"imgsz\": 640,\n",
        "    \"lr0\": 0.01,\n",
        "    \"batch\": 16,\n",
        "    \"num_classes\": 80,\n",
        "}\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
        "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
        "    \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n",
        "    \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "    \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\",\n",
        "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
        "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\",\n",
        "]\n",
        "\n",
        "CLASS_LABELS = {i: name for i, name in enumerate(COCO_CLASSES)}\n",
        "\n",
        "print(f\"COCO classes: {len(COCO_CLASSES)}개\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === COCO128 데이터셋 다운로드 ===\n",
        "\n",
        "data_info = check_det_dataset(\"coco128.yaml\")\n",
        "DATASET_DIR = data_info[\"path\"]\n",
        "print(f\"데이터셋 경로: {DATASET_DIR}\")\n",
        "\n",
        "train_images = glob.glob(f\"{DATASET_DIR}/images/train2017/*.jpg\")\n",
        "print(f\"Train 이미지: {len(train_images)}장\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 데이터셋 Artifact 생성 ===\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=CONFIG,\n",
        "    job_type=\"data-versioning\",\n",
        "    name=\"coco128-data-versioning\",\n",
        ")\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    \"coco128\",\n",
        "    type=\"dataset\",\n",
        "    description=\"COCO128 dataset (Ultralytics subset, 128 images, 80 classes)\",\n",
        "    metadata={\n",
        "        \"num_images\": len(train_images),\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"format\": \"YOLO\",\n",
        "        \"source\": \"Ultralytics COCO128\",\n",
        "    },\n",
        ")\n",
        "artifact.add_dir(DATASET_DIR)\n",
        "run.log_artifact(artifact)\n",
        "print(\"데이터셋 Artifact 로깅 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 샘플 이미지 + BBox 시각화 (wandb.Table) ===\n",
        "\n",
        "def parse_yolo_label(label_path, img_w, img_h):\n",
        "    \"\"\"YOLO format 라벨을 wandb box_data로 변환한다.\"\"\"\n",
        "    box_data = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return box_data\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cls_id = int(parts[0])\n",
        "            x_c, y_c, w, h = float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
        "            box_data.append({\n",
        "                \"position\": {\"middle\": [x_c, y_c], \"width\": w, \"height\": h},\n",
        "                \"class_id\": cls_id,\n",
        "                \"box_caption\": COCO_CLASSES[cls_id] if cls_id < len(COCO_CLASSES) else str(cls_id),\n",
        "            })\n",
        "    return box_data\n",
        "\n",
        "\n",
        "table = wandb.Table(columns=[\"Image with BBox\", \"Image\", \"Num Objects\", \"Classes\"])\n",
        "\n",
        "sample_images = random.sample(train_images, min(20, len(train_images)))\n",
        "\n",
        "for img_path in sample_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "    box_data = parse_yolo_label(label_path, img_w, img_h)\n",
        "\n",
        "    img_with_boxes = wandb.Image(\n",
        "        img,\n",
        "        boxes={\n",
        "            \"ground_truth\": {\n",
        "                \"box_data\": box_data,\n",
        "                \"class_labels\": CLASS_LABELS,\n",
        "            }\n",
        "        } if box_data else {},\n",
        "    )\n",
        "\n",
        "    class_names = list({bd[\"box_caption\"] for bd in box_data})\n",
        "\n",
        "    table.add_data(\n",
        "        img_with_boxes,\n",
        "        wandb.Image(img),\n",
        "        len(box_data),\n",
        "        \", \".join(class_names),\n",
        "    )\n",
        "\n",
        "wandb.log({\"dataset_preview\": table})\n",
        "wandb.finish()\n",
        "print(\"데이터셋 미리보기 테이블 로깅 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 모델 로드 (YOLOv8n) ===\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "print(model.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 학습 전 베이스라인 모델 등록 ===\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=CONFIG,\n",
        "    job_type=\"model-baseline\",\n",
        "    name=\"yolov8n-coco128-pretrained\",\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128:latest\")\n",
        "\n",
        "# pretrained 모델을 베이스라인으로 등록\n",
        "baseline_artifact = wandb.Artifact(\n",
        "    \"yolov8n-coco128\",\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n pretrained on COCO (baseline, before fine-tuning)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"detection\",\n",
        "        \"model_architecture\": \"yolov8n\",\n",
        "        \"dataset\": \"coco128\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"trained\": False,\n",
        "    },\n",
        ")\n",
        "baseline_artifact.add_file(\"yolov8n.pt\", name=\"best.pt\")\n",
        "run.log_artifact(baseline_artifact)\n",
        "\n",
        "run.link_artifact(\n",
        "    baseline_artifact,\n",
        "    f\"{WANDB_REGISTRY_NAME}/coco128-detector\",\n",
        "    aliases=[\"baseline\"],\n",
        ")\n",
        "print(\"학습 전 모델을 Registry에 'baseline' alias로 등록 완료!\")\n",
        "\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === YOLOv8n 학습 + W&B 메트릭 로깅 ===\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # Ultralytics 내장 콜백 비활성화 (수동 로깅 데모)\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=CONFIG,\n",
        "    job_type=\"training\",\n",
        "    name=\"yolov8n-coco128-train\",\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128:latest\")\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"coco128.yaml\",\n",
        "    epochs=CONFIG[\"epochs\"],\n",
        "    imgsz=CONFIG[\"imgsz\"],\n",
        "    lr0=CONFIG[\"lr0\"],\n",
        "    batch=CONFIG[\"batch\"],\n",
        "    project=\"runs/detect\",\n",
        "    name=\"coco128_train\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Ultralytics 학습 결과에서 에포크별 CSV 읽어서 W&B에 수동 로깅\n",
        "import csv\n",
        "\n",
        "csv_path = os.path.join(results.save_dir, \"results.csv\")\n",
        "if os.path.exists(csv_path):\n",
        "    with open(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            row = {k.strip(): v.strip() for k, v in row.items()}\n",
        "            wandb.log({\n",
        "                \"epoch\": int(row[\"epoch\"]),\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]),\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]),\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]),\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]),\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]),\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]),\n",
        "                \"val/precision\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"val/recall\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"val/mAP50\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"val/mAP50-95\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "            })\n",
        "\n",
        "BEST_PT_PATH = os.path.join(results.save_dir, \"weights/best.pt\")\n",
        "print(f\"Best model: {BEST_PT_PATH}\")\n",
        "print(f\"학습 완료! mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === Detection 결과 BBox 시각화 로깅 ===\n",
        "\n",
        "best_model = YOLO(BEST_PT_PATH)\n",
        "\n",
        "sample_for_viz = random.sample(train_images, min(16, len(train_images)))\n",
        "\n",
        "detection_images = []\n",
        "for img_path in sample_for_viz:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    preds = best_model(img_path, verbose=False)\n",
        "    box_data = []\n",
        "    for box in preds[0].boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        box_data.append({\n",
        "            \"position\": {\n",
        "                \"minX\": x1 / img_w,\n",
        "                \"minY\": y1 / img_h,\n",
        "                \"maxX\": x2 / img_w,\n",
        "                \"maxY\": y2 / img_h,\n",
        "            },\n",
        "            \"class_id\": int(box.cls),\n",
        "            \"scores\": {\"confidence\": float(box.conf)},\n",
        "            \"box_caption\": f\"{COCO_CLASSES[int(box.cls)]} {float(box.conf):.2f}\",\n",
        "        })\n",
        "\n",
        "    detection_images.append(\n",
        "        wandb.Image(\n",
        "            img,\n",
        "            boxes={\n",
        "                \"predictions\": {\n",
        "                    \"box_data\": box_data,\n",
        "                    \"class_labels\": CLASS_LABELS,\n",
        "                }\n",
        "            } if box_data else {},\n",
        "        )\n",
        "    )\n",
        "\n",
        "wandb.log({\"detection_results\": detection_images})\n",
        "print(f\"{len(sample_for_viz)}장의 이미지에 대한 detection 결과 로깅 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 예측 결과 wandb.Table ===\n",
        "\n",
        "pred_table = wandb.Table(columns=[\n",
        "    \"Image + BBox\", \"Rendered\", \"Num Objects\", \"Detected Classes\", \"Avg Confidence\",\n",
        "])\n",
        "\n",
        "eval_images = random.sample(train_images, min(50, len(train_images)))\n",
        "\n",
        "for img_path in eval_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    preds = best_model(img_path, verbose=False)\n",
        "    r = preds[0]\n",
        "\n",
        "    box_data = []\n",
        "    detected_classes = set()\n",
        "    confs = []\n",
        "\n",
        "    for box in r.boxes:\n",
        "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        box_data.append({\n",
        "            \"position\": {\n",
        "                \"minX\": x1 / img_w, \"minY\": y1 / img_h,\n",
        "                \"maxX\": x2 / img_w, \"maxY\": y2 / img_h,\n",
        "            },\n",
        "            \"class_id\": cls_id,\n",
        "            \"scores\": {\"confidence\": conf},\n",
        "            \"box_caption\": f\"{COCO_CLASSES[cls_id]} {conf:.2f}\",\n",
        "        })\n",
        "        detected_classes.add(COCO_CLASSES[cls_id])\n",
        "        confs.append(conf)\n",
        "\n",
        "    img_with_boxes = wandb.Image(\n",
        "        img,\n",
        "        boxes={\n",
        "            \"predictions\": {\n",
        "                \"box_data\": box_data,\n",
        "                \"class_labels\": CLASS_LABELS,\n",
        "            }\n",
        "        } if box_data else {},\n",
        "    )\n",
        "\n",
        "    rendered = Image.fromarray(r.plot()[..., ::-1])  # BGR -> RGB\n",
        "\n",
        "    avg_conf = np.mean(confs) if confs else 0.0\n",
        "    pred_table.add_data(\n",
        "        img_with_boxes,\n",
        "        wandb.Image(rendered),\n",
        "        len(r.boxes),\n",
        "        \", \".join(sorted(detected_classes)),\n",
        "        f\"{avg_conf:.2%}\",\n",
        "    )\n",
        "\n",
        "wandb.log({\"prediction_table\": pred_table})\n",
        "print(f\"예측 결과 테이블 ({len(eval_images)}장) 로깅 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === 모델 Artifact 저장 + Model Registry 등록 ===\n",
        "\n",
        "final_metrics = results.results_dict\n",
        "\n",
        "model_artifact = wandb.Artifact(\n",
        "    \"yolov8n-coco128\",\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n fine-tuned on COCO128\",\n",
        "    metadata={\n",
        "        \"model_type\": \"detection\",\n",
        "        \"model_architecture\": \"yolov8n\",\n",
        "        \"dataset\": \"coco128\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"trained\": True,\n",
        "        \"epochs\": CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": final_metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "        \"best_mAP50-95\": final_metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        \"best_precision\": final_metrics.get(\"metrics/precision(B)\", 0),\n",
        "        \"best_recall\": final_metrics.get(\"metrics/recall(B)\", 0),\n",
        "    },\n",
        ")\n",
        "model_artifact.add_file(BEST_PT_PATH, name=\"best.pt\")\n",
        "run.log_artifact(model_artifact)\n",
        "\n",
        "run.link_artifact(\n",
        "    model_artifact,\n",
        "    f\"{WANDB_REGISTRY_NAME}/coco128-detector\",\n",
        "    aliases=[\"staging\"],\n",
        ")\n",
        "print(\"학습된 모델을 Registry에 'staging' alias로 등록 완료!\")\n",
        "\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 하이퍼파라미터 Sweep\n",
        "\n",
        "W&B Sweeps를 사용하여 YOLOv8n의 하이퍼파라미터를 베이지안 최적화합니다.\n",
        "\n",
        "**탐색 파라미터:**\n",
        "- `lr0`: 초기 학습률 (1e-5 ~ 1e-2, log-uniform)\n",
        "- `imgsz`: 입력 이미지 크기 (320 / 640)\n",
        "- `augment`: 데이터 증강 활성화 여부\n",
        "\n",
        "**최적화 목표:** `val/mAP50` 최대화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === Sweep ===\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val/mAP50\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"lr0\": {\"min\": 1e-5, \"max\": 1e-2, \"distribution\": \"log_uniform_values\"},\n",
        "        \"imgsz\": {\"values\": [320, 640]},\n",
        "        \"augment\": {\"values\": [True, False]},\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def sweep_train():\n",
        "    run = wandb.init()\n",
        "    config = wandb.config\n",
        "\n",
        "    sweep_model = YOLO(\"yolov8n.pt\")\n",
        "    sweep_results = sweep_model.train(\n",
        "        data=\"coco128.yaml\",\n",
        "        epochs=3,\n",
        "        imgsz=config.imgsz,\n",
        "        lr0=config.lr0,\n",
        "        augment=config.augment,\n",
        "        batch=CONFIG[\"batch\"],\n",
        "        project=\"runs/detect_sweep\",\n",
        "        name=f\"sweep_{run.id}\",\n",
        "        exist_ok=True,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    metrics = sweep_results.results_dict\n",
        "    wandb.log({\n",
        "        \"val/mAP50\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "        \"val/mAP50-95\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        \"val/precision\": metrics.get(\"metrics/precision(B)\", 0),\n",
        "        \"val/recall\": metrics.get(\"metrics/recall(B)\", 0),\n",
        "    })\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=5)\n",
        "print(\"Sweep 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === W&B Report 생성 ===\n",
        "\n",
        "import wandb_workspaces.reports.v2 as wr\n",
        "\n",
        "report = wr.Report(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    title=\"COCO128 Object Detection — 실험 결과 리포트\",\n",
        "    description=\"YOLOv8n COCO128 fine-tuning 실험 결과 및 Sweep 분석\",\n",
        ")\n",
        "\n",
        "report.blocks = [\n",
        "    wr.TableOfContents(),\n",
        "\n",
        "    wr.H1(\"1. 실험 개요\"),\n",
        "    wr.P(\n",
        "        \"COCO128 데이터셋에 대한 YOLOv8n 객체 탐지 실험 결과를 정리합니다. \"\n",
        "        \"W&B의 Experiment Tracking, Artifacts, Sweeps, Model Registry, Media Logging 기능을 활용하였습니다.\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"2. 학습 결과\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[\n",
        "            wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)\n",
        "        ],\n",
        "        panels=[\n",
        "            wr.LinePlot(title=\"Box Loss (Train)\", x=\"epoch\", y=[\"train/box_loss\"]),\n",
        "            wr.LinePlot(title=\"Box Loss (Val)\", x=\"epoch\", y=[\"val/box_loss\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5\", x=\"epoch\", y=[\"val/mAP50\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5:0.95\", x=\"epoch\", y=[\"val/mAP50-95\"]),\n",
        "            wr.LinePlot(title=\"Precision\", x=\"epoch\", y=[\"val/precision\"]),\n",
        "            wr.LinePlot(title=\"Recall\", x=\"epoch\", y=[\"val/recall\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"3. Sweep 분석\"),\n",
        "    wr.P(\"Bayesian 최적화를 통한 하이퍼파라미터 탐색 결과:\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[\n",
        "            wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)\n",
        "        ],\n",
        "        panels=[\n",
        "            wr.ParallelCoordinatesPlot(\n",
        "                columns=[\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lr0\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::imgsz\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::augment\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"val/mAP50\"),\n",
        "                ],\n",
        "            ),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5\", metric=\"val/mAP50\"),\n",
        "            wr.BarPlot(title=\"mAP@0.5 by Run\", metrics=[\"val/mAP50\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"4. 다음 단계\"),\n",
        "    wr.P(\n",
        "        \"최적 모델을 Model Registry의 'production' alias로 승격하여 \"\n",
        "        \"배포 파이프라인을 트리거합니다.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "report.save()\n",
        "print(f\"Report 생성 완료! URL: {report.url}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "wandb.finish()\n",
        "print(\"모든 W&B 리소스가 정리되었습니다. 데모 완료!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}