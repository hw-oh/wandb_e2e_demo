{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hw-oh/wandb_e2e_demo/blob/main/models/image_detection/image_detection.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q wandb ultralytics wandb-workspaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "WANDB_API_KEY = userdata.get(\"WANDB_API_KEY\")\n",
        "WANDB_ENTITY = userdata.get(\"WANDB_ENTITY\")\n",
        "WANDB_PROJECT = userdata.get(\"WANDB_PROJECT\")\n",
        "WANDB_REGISTRY_NAME = userdata.get(\"WANDB_REGISTRY_NAME\")\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "wandb.login(key=WANDB_API_KEY)\n",
        "print(f\"Entity: {WANDB_ENTITY}\")\n",
        "print(f\"Project: {WANDB_PROJECT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unified Vision Demo — YOLOv8-seg로 Classification + Detection + Segmentation\n",
        "\n",
        "## 개요\n",
        "\n",
        "이 노트북은 **COCO128-seg** 데이터셋과 **YOLOv8n-seg** 모델을 사용하여\n",
        "하나의 모델로 **Classification(분류)**, **Detection(탐지)**, **Segmentation(분할)** 을\n",
        "모두 수행하면서 W&B의 핵심 기능을 전부 체험합니다.\n",
        "\n",
        "### 왜 YOLOv8-seg인가?\n",
        "\n",
        "YOLOv8-seg는 한 번의 추론으로 세 가지 결과를 동시에 제공합니다:\n",
        "- **Classification**: 검출된 객체의 클래스 분류\n",
        "- **Detection**: 바운딩 박스 좌표 + 클래스 + 신뢰도\n",
        "- **Segmentation**: 인스턴스별 픽셀 마스크\n",
        "\n",
        "### 모델 버전 관리 흐름\n",
        "\n",
        "| 단계 | Artifact Alias | 설명 |\n",
        "|------|---------------|------|\n",
        "| Xavier 초기화 | `xavier-init` | 학습 전 랜덤 초기화 모델 (기준점) |\n",
        "| Baseline 학습 | `baseline` | 기본 하이퍼파라미터로 학습한 모델 |\n",
        "| Sweep 최적화 | `latest` | Sweep으로 찾은 최적 하이퍼파라미터로 학습한 모델 |\n",
        "\n",
        "## 다루는 W&B 기능\n",
        "\n",
        "| 기능 | 설명 |\n",
        "|------|------|\n",
        "| **Experiment Tracking** | 학습 메트릭 실시간 추적 (`wandb.init`, `wandb.log`, `wandb.config`) |\n",
        "| **Media Logging** | BBox + Mask 인터랙티브 시각화 (`wandb.Image`) |\n",
        "| **Tables** | 예측 결과 + mIoU 비교 (`wandb.Table`) |\n",
        "| **Artifacts** | 데이터셋/모델 버저닝 및 계보(lineage) 추적 |\n",
        "| **Model Registry** | 모델 등록 및 alias 관리 (UI에서 수행) |\n",
        "| **Sweeps** | 베이지안 하이퍼파라미터 최적화 + 튜닝 효과 검증 |\n",
        "| **Reports** | 프로그래밍 방식 실험 리포트 생성 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "from ultralytics.data.utils import check_det_dataset\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import glob\n",
        "import csv\n",
        "\n",
        "BASELINE_CONFIG = {\n",
        "    \"model_name\": \"yolov8n-seg\",\n",
        "    \"dataset\": \"coco128-seg\",\n",
        "    \"epochs\": 30,\n",
        "    \"imgsz\": 640,\n",
        "    \"lr0\": 0.01,\n",
        "    \"batch\": 16,\n",
        "    \"num_classes\": 80,\n",
        "}\n",
        "\n",
        "COCO_CLASSES = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\",\n",
        "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\",\n",
        "    \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\",\n",
        "    \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\",\n",
        "    \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
        "    \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\",\n",
        "    \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\",\n",
        "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
        "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\",\n",
        "]\n",
        "\n",
        "CLASS_LABELS = {i: name for i, name in enumerate(COCO_CLASSES)}\n",
        "MASK_CLASS_LABELS = {0: \"background\"}\n",
        "MASK_CLASS_LABELS.update({i + 1: name for i, name in enumerate(COCO_CLASSES)})\n",
        "\n",
        "ARTIFACT_NAME = \"yolov8n-seg-coco128\"\n",
        "\n",
        "print(f\"COCO classes: {len(COCO_CLASSES)}개\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 헬퍼 함수 ===\n",
        "\n",
        "def parse_yolo_seg_label(label_path):\n",
        "    \"\"\"YOLO-seg 라벨에서 class_id와 polygon을 파싱한다.\"\"\"\n",
        "    objects = []\n",
        "    if not os.path.exists(label_path):\n",
        "        return objects\n",
        "    with open(label_path) as f:\n",
        "        for line in f.readlines():\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 7:\n",
        "                continue\n",
        "            cls_id = int(parts[0])\n",
        "            coords = [float(x) for x in parts[1:]]\n",
        "            xs, ys = coords[0::2], coords[1::2]\n",
        "            objects.append({\n",
        "                \"cls_id\": cls_id,\n",
        "                \"polygon\": list(zip(xs, ys)),\n",
        "                \"bbox\": {\"x_min\": min(xs), \"y_min\": min(ys), \"x_max\": max(xs), \"y_max\": max(ys)},\n",
        "            })\n",
        "    return objects\n",
        "\n",
        "\n",
        "def polygons_to_mask(objects, img_w, img_h):\n",
        "    \"\"\"GT 오브젝트 리스트를 클래스별 마스크(2D int array)로 변환한다.\"\"\"\n",
        "    mask = np.zeros((img_h, img_w), dtype=np.int32)\n",
        "    for obj in objects:\n",
        "        pts = [(x * img_w, y * img_h) for x, y in obj[\"polygon\"]]\n",
        "        if len(pts) >= 3:\n",
        "            pil_mask = Image.new(\"L\", (img_w, img_h), 0)\n",
        "            ImageDraw.Draw(pil_mask).polygon(pts, fill=1)\n",
        "            mask[np.array(pil_mask) > 0] = obj[\"cls_id\"] + 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "def pred_to_mask(r, img_w, img_h):\n",
        "    \"\"\"YOLO 예측 결과를 클래스별 마스크(2D int array)로 변환한다.\"\"\"\n",
        "    mask = np.zeros((img_h, img_w), dtype=np.int32)\n",
        "    if r.masks is None:\n",
        "        return mask\n",
        "    for poly_xy, box in zip(r.masks.xy, r.boxes):\n",
        "        pts = [(float(p[0]), float(p[1])) for p in poly_xy]\n",
        "        if len(pts) >= 3:\n",
        "            pil_mask = Image.new(\"L\", (img_w, img_h), 0)\n",
        "            ImageDraw.Draw(pil_mask).polygon(pts, fill=1)\n",
        "            mask[np.array(pil_mask) > 0] = int(box.cls) + 1\n",
        "    return mask\n",
        "\n",
        "\n",
        "def compute_miou(gt_mask, pred_mask):\n",
        "    \"\"\"GT 마스크와 예측 마스크의 mIoU를 계산한다.\"\"\"\n",
        "    classes = set(np.unique(gt_mask)) | set(np.unique(pred_mask))\n",
        "    classes.discard(0)\n",
        "    if not classes:\n",
        "        return 0.0\n",
        "    ious = []\n",
        "    for c in classes:\n",
        "        inter = np.logical_and(gt_mask == c, pred_mask == c).sum()\n",
        "        union = np.logical_or(gt_mask == c, pred_mask == c).sum()\n",
        "        if union > 0:\n",
        "            ious.append(inter / union)\n",
        "    return float(np.mean(ious)) if ious else 0.0\n",
        "\n",
        "\n",
        "def build_prediction_table(yolo_model, image_paths):\n",
        "    \"\"\"모델 예측 결과를 wandb.Table로 생성한다.\"\"\"\n",
        "    table = wandb.Table(columns=[\n",
        "        \"Detection\", \"Segmentation\", \"Detected Classes\",\n",
        "        \"Num Objects\", \"Avg Confidence\", \"mIoU\",\n",
        "    ])\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = Image.open(img_path)\n",
        "        img_w, img_h = img.size\n",
        "        r = yolo_model(img_path, verbose=False)[0]\n",
        "\n",
        "        # --- Detection column (인터랙티브 BBox) ---\n",
        "        box_data, detected_classes, confs = [], set(), []\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "            cls_id, conf = int(box.cls), float(box.conf)\n",
        "            box_data.append({\n",
        "                \"position\": {\"minX\": x1/img_w, \"minY\": y1/img_h, \"maxX\": x2/img_w, \"maxY\": y2/img_h},\n",
        "                \"class_id\": cls_id,\n",
        "                \"scores\": {\"confidence\": conf},\n",
        "                \"box_caption\": f\"{COCO_CLASSES[cls_id]} {conf:.2f}\",\n",
        "            })\n",
        "            detected_classes.add(COCO_CLASSES[cls_id])\n",
        "            confs.append(conf)\n",
        "        det_img = wandb.Image(\n",
        "            img,\n",
        "            boxes={\"predictions\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "        )\n",
        "\n",
        "        # --- Segmentation column (인터랙티브 마스크: 클래스별 on/off 가능) ---\n",
        "        pred_mask = pred_to_mask(r, img_w, img_h)\n",
        "        seg_img = wandb.Image(\n",
        "            img,\n",
        "            masks={\"predictions\": {\"mask_data\": pred_mask, \"class_labels\": MASK_CLASS_LABELS}},\n",
        "        )\n",
        "\n",
        "        # --- mIoU (GT 라벨 대비) ---\n",
        "        label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "        gt_objects = parse_yolo_seg_label(label_path)\n",
        "        gt_mask = polygons_to_mask(gt_objects, img_w, img_h)\n",
        "        miou = compute_miou(gt_mask, pred_mask)\n",
        "\n",
        "        avg_conf = float(np.mean(confs)) if confs else 0.0\n",
        "        table.add_data(\n",
        "            det_img, seg_img, \", \".join(sorted(detected_classes)),\n",
        "            len(r.boxes), f\"{avg_conf:.2%}\", round(miou, 4),\n",
        "        )\n",
        "\n",
        "    return table\n",
        "\n",
        "\n",
        "def log_training_metrics(results_save_dir):\n",
        "    \"\"\"YOLO 학습 결과 CSV를 W&B에 로깅한다.\"\"\"\n",
        "    csv_path = os.path.join(results_save_dir, \"results.csv\")\n",
        "    if not os.path.exists(csv_path):\n",
        "        return\n",
        "    with open(csv_path) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            row = {k.strip(): v.strip() for k, v in row.items()}\n",
        "            wandb.log({\n",
        "                \"epoch\": int(row[\"epoch\"]),\n",
        "                \"train/box_loss\": float(row[\"train/box_loss\"]),\n",
        "                \"train/seg_loss\": float(row[\"train/seg_loss\"]),\n",
        "                \"train/cls_loss\": float(row[\"train/cls_loss\"]),\n",
        "                \"train/dfl_loss\": float(row[\"train/dfl_loss\"]),\n",
        "                \"val/box_loss\": float(row[\"val/box_loss\"]),\n",
        "                \"val/seg_loss\": float(row[\"val/seg_loss\"]),\n",
        "                \"val/cls_loss\": float(row[\"val/cls_loss\"]),\n",
        "                \"val/dfl_loss\": float(row[\"val/dfl_loss\"]),\n",
        "                \"val/mAP50_box\": float(row[\"metrics/mAP50(B)\"]),\n",
        "                \"val/mAP50-95_box\": float(row[\"metrics/mAP50-95(B)\"]),\n",
        "                \"val/precision_box\": float(row[\"metrics/precision(B)\"]),\n",
        "                \"val/recall_box\": float(row[\"metrics/recall(B)\"]),\n",
        "                \"val/mAP50_mask\": float(row[\"metrics/mAP50(M)\"]),\n",
        "                \"val/mAP50-95_mask\": float(row[\"metrics/mAP50-95(M)\"]),\n",
        "            })\n",
        "\n",
        "\n",
        "print(\"헬퍼 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 데이터셋 준비 + Artifact 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_info = check_det_dataset(\"coco128-seg.yaml\")\n",
        "DATASET_DIR = data_info[\"path\"]\n",
        "train_images = glob.glob(f\"{DATASET_DIR}/images/train2017/*.jpg\")\n",
        "print(f\"데이터셋 경로: {DATASET_DIR}\")\n",
        "print(f\"Train 이미지: {len(train_images)}장\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"data-versioning\",\n",
        "    name=\"coco128-seg-data-versioning\",\n",
        ")\n",
        "\n",
        "artifact = wandb.Artifact(\n",
        "    \"coco128-seg\",\n",
        "    type=\"dataset\",\n",
        "    description=\"COCO128-seg dataset (128 images, 80 classes, instance segmentation labels)\",\n",
        "    metadata={\n",
        "        \"num_images\": len(train_images),\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"format\": \"YOLO-seg\",\n",
        "    },\n",
        ")\n",
        "artifact.add_dir(DATASET_DIR)\n",
        "run.log_artifact(artifact)\n",
        "\n",
        "# GT BBox + Mask 시각화 테이블\n",
        "table = wandb.Table(columns=[\"GT Overlay\", \"Num Objects\", \"Classes\"])\n",
        "sample_images = random.sample(train_images, min(20, len(train_images)))\n",
        "\n",
        "for img_path in sample_images:\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "    label_path = img_path.replace(\"/images/\", \"/labels/\").replace(\".jpg\", \".txt\")\n",
        "    gt_objects = parse_yolo_seg_label(label_path)\n",
        "\n",
        "    box_data = []\n",
        "    for obj in gt_objects:\n",
        "        bb = obj[\"bbox\"]\n",
        "        box_data.append({\n",
        "            \"position\": {\"minX\": bb[\"x_min\"], \"minY\": bb[\"y_min\"], \"maxX\": bb[\"x_max\"], \"maxY\": bb[\"y_max\"]},\n",
        "            \"class_id\": obj[\"cls_id\"],\n",
        "            \"box_caption\": COCO_CLASSES[obj[\"cls_id\"]] if obj[\"cls_id\"] < len(COCO_CLASSES) else str(obj[\"cls_id\"]),\n",
        "        })\n",
        "\n",
        "    gt_mask = polygons_to_mask(gt_objects, img_w, img_h)\n",
        "    gt_img = wandb.Image(\n",
        "        img,\n",
        "        boxes={\"ground_truth\": {\"box_data\": box_data, \"class_labels\": CLASS_LABELS}} if box_data else {},\n",
        "        masks={\"ground_truth\": {\"mask_data\": gt_mask, \"class_labels\": MASK_CLASS_LABELS}},\n",
        "    )\n",
        "    class_names = list({COCO_CLASSES[o[\"cls_id\"]] for o in gt_objects})\n",
        "    table.add_data(gt_img, len(gt_objects), \", \".join(class_names))\n",
        "\n",
        "wandb.log({\"dataset_preview\": table})\n",
        "wandb.finish()\n",
        "print(\"데이터셋 Artifact + GT 시각화 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Xavier 초기화 모델 등록\n",
        "\n",
        "학습을 시작하기 전, **Xavier 초기화**만 적용한 모델을 Artifact로 등록합니다.\n",
        "이 모델은 아무것도 학습하지 않은 상태이므로, 학습 전후의 성능 차이를 명확하게 보여주는 기준점 역할을 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"model-init\",\n",
        "    name=\"yolov8n-seg-xavier-init\",\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128-seg:latest\")\n",
        "\n",
        "init_model = YOLO(\"yolov8n-seg.yaml\")\n",
        "\n",
        "for m in init_model.model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "XAVIER_PT = \"yolov8n-seg-xavier.pt\"\n",
        "torch.save({\"model\": init_model.model}, XAVIER_PT)\n",
        "\n",
        "xavier_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg with Xavier initialization (no training)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"initialization\": \"xavier_uniform\",\n",
        "        \"trained\": False,\n",
        "        \"best_mAP50\": 0.0,\n",
        "        \"best_mAP50_mask\": 0.0,\n",
        "    },\n",
        ")\n",
        "xavier_artifact.add_file(XAVIER_PT, name=\"best.pt\")\n",
        "run.log_artifact(xavier_artifact, aliases=[\"xavier-init\"])\n",
        "\n",
        "# Model Registry 등록 — UI에서 직접 수행합니다\n",
        "# run.link_artifact(\n",
        "#     xavier_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"xavier-init\"],\n",
        "# )\n",
        "\n",
        "print(\"Xavier 초기화 모델 Artifact 등록 완료! (alias: xavier-init)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Baseline 학습 — 기본 하이퍼파라미터\n",
        "\n",
        "기본 하이퍼파라미터(`lr0=0.01`, `batch=16`)로 YOLOv8n-seg를 학습합니다.\n",
        "이 결과를 기준점(baseline)으로 삼아, Sweep을 통해 얼마나 개선되는지 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=BASELINE_CONFIG,\n",
        "    job_type=\"training\",\n",
        "    name=\"baseline-yolov8n-seg\",\n",
        "    tags=[\"baseline\"],\n",
        ")\n",
        "\n",
        "data_artifact = run.use_artifact(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/coco128-seg:latest\")\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=BASELINE_CONFIG[\"imgsz\"],\n",
        "    lr0=BASELINE_CONFIG[\"lr0\"],\n",
        "    batch=BASELINE_CONFIG[\"batch\"],\n",
        "    project=\"runs/segment\",\n",
        "    name=\"baseline\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "log_training_metrics(results.save_dir)\n",
        "\n",
        "BASELINE_BEST_PT = os.path.join(results.save_dir, \"weights/best.pt\")\n",
        "baseline_metrics = results.results_dict\n",
        "baseline_mAP50_box = baseline_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "baseline_mAP50_mask = baseline_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"Baseline 학습 완료!\")\n",
        "print(f\"  mAP50 (Box):  {baseline_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {baseline_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = YOLO(BASELINE_BEST_PT)\n",
        "eval_images = random.sample(train_images, min(30, len(train_images)))\n",
        "\n",
        "pred_table = build_prediction_table(best_model, eval_images)\n",
        "wandb.log({\"prediction_table\": pred_table})\n",
        "print(f\"Prediction Table ({len(eval_images)}장) 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=\"YOLOv8n-seg baseline on COCO128-seg (default hyperparameters)\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": baseline_mAP50_box,\n",
        "        \"best_mAP50_mask\": baseline_mAP50_mask,\n",
        "        \"sweep_tuned\": False,\n",
        "    },\n",
        ")\n",
        "baseline_artifact.add_file(BASELINE_BEST_PT, name=\"best.pt\")\n",
        "run.log_artifact(baseline_artifact, aliases=[\"baseline\"])\n",
        "\n",
        "# Model Registry 등록 — UI에서 직접 수행합니다\n",
        "# run.link_artifact(\n",
        "#     baseline_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"baseline\"],\n",
        "# )\n",
        "\n",
        "print(\"Baseline 모델 Artifact 등록 완료! (alias: baseline)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. W&B Sweep — 하이퍼파라미터 최적화\n",
        "\n",
        "W&B Sweeps의 **베이지안 최적화**를 사용하여 최적의 하이퍼파라미터를 탐색합니다.\n",
        "여러 번의 Sweep run을 통해 최적 조합을 찾아가는 과정을 관찰하세요.\n",
        "\n",
        "**탐색 파라미터:**\n",
        "- `lr0`: 초기 학습률 (0.001 ~ 0.02)\n",
        "- `lrf`: 최종 학습률 비율 (0.01 ~ 0.2)\n",
        "- `momentum`: SGD 모멘텀 (0.85 ~ 0.98)\n",
        "- `weight_decay`: 가중치 감쇠 (0.0001 ~ 0.001)\n",
        "- `warmup_epochs`: 웜업 에포크 수 (1, 2, 3)\n",
        "- `mosaic`: 모자이크 증강 비율 (0.5 ~ 1.0)\n",
        "\n",
        "**최적화 목표:** `val/mAP50_box` 최대화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val/mAP50_box\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \"lr0\": {\"min\": 0.001, \"max\": 0.02},\n",
        "        \"lrf\": {\"min\": 0.01, \"max\": 0.2},\n",
        "        \"momentum\": {\"min\": 0.85, \"max\": 0.98},\n",
        "        \"weight_decay\": {\"min\": 0.0001, \"max\": 0.001},\n",
        "        \"warmup_epochs\": {\"values\": [1, 2, 3]},\n",
        "        \"mosaic\": {\"min\": 0.5, \"max\": 1.0},\n",
        "    },\n",
        "}\n",
        "\n",
        "SWEEP_EPOCHS = 10\n",
        "\n",
        "\n",
        "def sweep_train():\n",
        "    run = wandb.init()\n",
        "    cfg = wandb.config\n",
        "\n",
        "    sweep_model = YOLO(\"yolov8n-seg.pt\")\n",
        "    sweep_results = sweep_model.train(\n",
        "        data=\"coco128-seg.yaml\",\n",
        "        epochs=SWEEP_EPOCHS,\n",
        "        imgsz=640,\n",
        "        lr0=cfg.lr0,\n",
        "        lrf=cfg.lrf,\n",
        "        momentum=cfg.momentum,\n",
        "        weight_decay=cfg.weight_decay,\n",
        "        warmup_epochs=cfg.warmup_epochs,\n",
        "        mosaic=cfg.mosaic,\n",
        "        batch=16,\n",
        "        project=\"runs/segment_sweep\",\n",
        "        name=f\"sweep_{run.id}\",\n",
        "        exist_ok=True,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    metrics = sweep_results.results_dict\n",
        "    wandb.log({\n",
        "        \"val/mAP50_box\": metrics.get(\"metrics/mAP50(B)\", 0),\n",
        "        \"val/mAP50-95_box\": metrics.get(\"metrics/mAP50-95(B)\", 0),\n",
        "        \"val/precision_box\": metrics.get(\"metrics/precision(B)\", 0),\n",
        "        \"val/recall_box\": metrics.get(\"metrics/recall(B)\", 0),\n",
        "        \"val/mAP50_mask\": metrics.get(\"metrics/mAP50(M)\", 0),\n",
        "        \"val/mAP50-95_mask\": metrics.get(\"metrics/mAP50-95(M)\", 0),\n",
        "    })\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
        "wandb.agent(sweep_id, function=sweep_train, count=10)\n",
        "print(\"Sweep 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Sweep 최적 하이퍼파라미터로 Full Training\n",
        "\n",
        "Sweep에서 찾은 최적의 하이퍼파라미터로 full epoch 학습을 실행합니다.\n",
        "Baseline과 비교하여 Sweep의 효과를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api = wandb.Api()\n",
        "sweep = api.sweep(f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{sweep_id}\")\n",
        "best_run = sweep.best_run()\n",
        "best_config = best_run.config\n",
        "\n",
        "print(\"Sweep 최적 하이퍼파라미터:\")\n",
        "for k, v in best_config.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(f\"  Best mAP50 (Box): {best_run.summary.get('val/mAP50_box', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_config = {**BASELINE_CONFIG, **best_config}\n",
        "tuned_config[\"sweep_tuned\"] = True\n",
        "tuned_config[\"sweep_id\"] = sweep_id\n",
        "\n",
        "run = wandb.init(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    config=tuned_config,\n",
        "    job_type=\"training\",\n",
        "    name=\"tuned-yolov8n-seg\",\n",
        "    tags=[\"sweep-tuned\"],\n",
        ")\n",
        "\n",
        "tuned_model = YOLO(\"yolov8n-seg.pt\")\n",
        "tuned_results = tuned_model.train(\n",
        "    data=\"coco128-seg.yaml\",\n",
        "    epochs=BASELINE_CONFIG[\"epochs\"],\n",
        "    imgsz=640,\n",
        "    lr0=best_config.get(\"lr0\", 0.01),\n",
        "    lrf=best_config.get(\"lrf\", 0.01),\n",
        "    momentum=best_config.get(\"momentum\", 0.937),\n",
        "    weight_decay=best_config.get(\"weight_decay\", 0.0005),\n",
        "    warmup_epochs=best_config.get(\"warmup_epochs\", 3),\n",
        "    mosaic=best_config.get(\"mosaic\", 1.0),\n",
        "    batch=16,\n",
        "    project=\"runs/segment\",\n",
        "    name=\"tuned\",\n",
        "    exist_ok=True,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "log_training_metrics(tuned_results.save_dir)\n",
        "\n",
        "TUNED_BEST_PT = os.path.join(tuned_results.save_dir, \"weights/best.pt\")\n",
        "tuned_metrics = tuned_results.results_dict\n",
        "tuned_mAP50_box = tuned_metrics.get(\"metrics/mAP50(B)\", 0)\n",
        "tuned_mAP50_mask = tuned_metrics.get(\"metrics/mAP50(M)\", 0)\n",
        "\n",
        "print(f\"Tuned 학습 완료!\")\n",
        "print(f\"  mAP50 (Box):  {tuned_mAP50_box:.4f}\")\n",
        "print(f\"  mAP50 (Mask): {tuned_mAP50_mask:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuned_best_model = YOLO(TUNED_BEST_PT)\n",
        "eval_images_tuned = random.sample(train_images, min(30, len(train_images)))\n",
        "\n",
        "pred_table_tuned = build_prediction_table(tuned_best_model, eval_images_tuned)\n",
        "wandb.log({\"prediction_table\": pred_table_tuned})\n",
        "print(f\"Tuned Prediction Table ({len(eval_images_tuned)}장) 로깅 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Baseline vs Sweep-Tuned 비교\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "box_diff = tuned_mAP50_box - baseline_mAP50_box\n",
        "mask_diff = tuned_mAP50_mask - baseline_mAP50_mask\n",
        "\n",
        "print(f\"{'Metric':<20} {'Baseline':>10} {'Tuned':>10} {'Diff':>10}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'mAP50 (Box)':<20} {baseline_mAP50_box:>10.4f} {tuned_mAP50_box:>10.4f} {box_diff:>+10.4f}\")\n",
        "print(f\"{'mAP50 (Mask)':<20} {baseline_mAP50_mask:>10.4f} {tuned_mAP50_mask:>10.4f} {mask_diff:>+10.4f}\")\n",
        "\n",
        "wandb.log({\n",
        "    \"comparison/baseline_mAP50_box\": baseline_mAP50_box,\n",
        "    \"comparison/tuned_mAP50_box\": tuned_mAP50_box,\n",
        "    \"comparison/improvement_mAP50_box\": box_diff,\n",
        "    \"comparison/baseline_mAP50_mask\": baseline_mAP50_mask,\n",
        "    \"comparison/tuned_mAP50_mask\": tuned_mAP50_mask,\n",
        "    \"comparison/improvement_mAP50_mask\": mask_diff,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_mAP50 = max(tuned_mAP50_box, baseline_mAP50_box)\n",
        "final_mAP50_mask = max(tuned_mAP50_mask, baseline_mAP50_mask)\n",
        "final_pt = TUNED_BEST_PT if tuned_mAP50_box >= baseline_mAP50_box else BASELINE_BEST_PT\n",
        "is_tuned_better = tuned_mAP50_box >= baseline_mAP50_box\n",
        "\n",
        "print(f\"최종 모델: {'Tuned' if is_tuned_better else 'Baseline'} (mAP50 Box: {final_mAP50:.4f})\")\n",
        "\n",
        "model_artifact = wandb.Artifact(\n",
        "    ARTIFACT_NAME,\n",
        "    type=\"model\",\n",
        "    description=f\"YOLOv8n-seg {'sweep-tuned' if is_tuned_better else 'baseline'} on COCO128-seg\",\n",
        "    metadata={\n",
        "        \"model_type\": \"yolo-seg\",\n",
        "        \"model_architecture\": \"yolov8n-seg\",\n",
        "        \"dataset\": \"coco128-seg\",\n",
        "        \"num_classes\": 80,\n",
        "        \"classes\": COCO_CLASSES,\n",
        "        \"framework\": \"ultralytics\",\n",
        "        \"input_size\": [3, 640, 640],\n",
        "        \"epochs\": BASELINE_CONFIG[\"epochs\"],\n",
        "        \"best_mAP50\": final_mAP50,\n",
        "        \"best_mAP50_mask\": final_mAP50_mask,\n",
        "        \"sweep_tuned\": is_tuned_better,\n",
        "    },\n",
        ")\n",
        "model_artifact.add_file(final_pt, name=\"best.pt\")\n",
        "run.log_artifact(model_artifact, aliases=[\"latest\"])\n",
        "\n",
        "# Model Registry 등록 — UI에서 직접 수행합니다\n",
        "# run.link_artifact(\n",
        "#     model_artifact,\n",
        "#     f\"{WANDB_REGISTRY_NAME}/coco128-vision\",\n",
        "#     aliases=[\"staging\"],\n",
        "# )\n",
        "\n",
        "print(\"최종 모델 Artifact 등록 완료! (alias: latest)\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. W&B Report 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wandb_workspaces.reports.v2 as wr\n",
        "\n",
        "report = wr.Report(\n",
        "    entity=WANDB_ENTITY,\n",
        "    project=WANDB_PROJECT,\n",
        "    title=\"Unified Vision — YOLOv8n-seg 실험 결과 리포트\",\n",
        "    description=\"YOLOv8n-seg COCO128 학습 + Sweep 하이퍼파라미터 튜닝 결과\",\n",
        ")\n",
        "\n",
        "report.blocks = [\n",
        "    wr.TableOfContents(),\n",
        "\n",
        "    wr.H1(\"1. 실험 개요\"),\n",
        "    wr.P(\n",
        "        \"COCO128-seg 데이터셋에 대한 YOLOv8n-seg 통합 비전 모델 실험 결과를 정리합니다. \"\n",
        "        \"하나의 모델로 Classification, Detection, Segmentation을 모두 수행합니다. \"\n",
        "        \"W&B의 Experiment Tracking, Artifacts, Sweeps, Model Registry, Media Logging 기능을 활용하였습니다.\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"2. Baseline 학습 결과\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)],\n",
        "        panels=[\n",
        "            wr.LinePlot(title=\"Box Loss (Train)\", x=\"epoch\", y=[\"train/box_loss\"]),\n",
        "            wr.LinePlot(title=\"Seg Loss (Train)\", x=\"epoch\", y=[\"train/seg_loss\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Box)\", x=\"epoch\", y=[\"val/mAP50_box\"]),\n",
        "            wr.LinePlot(title=\"mAP@0.5 (Mask)\", x=\"epoch\", y=[\"val/mAP50_mask\"]),\n",
        "            wr.LinePlot(title=\"Precision (Box)\", x=\"epoch\", y=[\"val/precision_box\"]),\n",
        "            wr.LinePlot(title=\"Recall (Box)\", x=\"epoch\", y=[\"val/recall_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"3. Sweep 분석\"),\n",
        "    wr.P(\"Bayesian 최적화를 통한 하이퍼파라미터 탐색 결과:\"),\n",
        "    wr.PanelGrid(\n",
        "        runsets=[wr.Runset(entity=WANDB_ENTITY, project=WANDB_PROJECT)],\n",
        "        panels=[\n",
        "            wr.ParallelCoordinatesPlot(\n",
        "                columns=[\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lr0\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lrf\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::momentum\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::weight_decay\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::mosaic\"),\n",
        "                    wr.ParallelCoordinatesPlotColumn(metric=\"val/mAP50_box\"),\n",
        "                ],\n",
        "            ),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Box)\", metric=\"val/mAP50_box\"),\n",
        "            wr.ScalarChart(title=\"Best mAP@0.5 (Mask)\", metric=\"val/mAP50_mask\"),\n",
        "            wr.BarPlot(title=\"mAP@0.5 by Run\", metrics=[\"val/mAP50_box\"]),\n",
        "        ],\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"4. Baseline vs Sweep-Tuned 비교\"),\n",
        "    wr.P(\n",
        "        f\"Baseline mAP50 (Box): {baseline_mAP50_box:.4f} → \"\n",
        "        f\"Tuned mAP50 (Box): {tuned_mAP50_box:.4f} \"\n",
        "        f\"(차이: {box_diff:+.4f})\"\n",
        "    ),\n",
        "\n",
        "    wr.H1(\"5. 다음 단계\"),\n",
        "    wr.P(\n",
        "        \"최적 모델을 Model Registry의 'production' alias로 승격하여 \"\n",
        "        \"Automation → GitHub Actions → Streamlit 배포 파이프라인을 트리거합니다.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "report.save()\n",
        "print(f\"Report 생성 완료! URL: {report.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Production 승격 (Automation 트리거)\n",
        "\n",
        "아래 셀을 실행하면 Model Registry에서 최신 모델을 `production` alias로 승격합니다.\n",
        "\n",
        "W&B Automation이 설정되어 있으면:\n",
        "1. `production` alias 추가 이벤트 발생\n",
        "2. Webhook → GitHub `repository_dispatch` 트리거\n",
        "3. GitHub Actions가 `deployment.json` 업데이트 → git push\n",
        "4. Streamlit Cloud 앱이 새 모델로 자동 배포\n",
        "\n",
        "**참고**: W&B UI에서 수동으로 `production` alias를 추가해도 동일하게 동작합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# api = wandb.Api()\n",
        "# artifact_path = f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{ARTIFACT_NAME}:latest\"\n",
        "#\n",
        "# try:\n",
        "#     art = api.artifact(artifact_path)\n",
        "#     art.aliases.append(\"production\")\n",
        "#     art.save()\n",
        "#     print(f\"'{artifact_path}'에 'production' alias 추가 완료!\")\n",
        "#     print(\"W&B Automation이 설정되어 있으면 배포 파이프라인이 자동으로 트리거됩니다.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Production 승격 실패: {e}\")\n",
        "#     print(\"W&B UI에서 수동으로 'production' alias를 추가해 주세요.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()\n",
        "print(\"모든 W&B 리소스가 정리되었습니다. 데모 완료!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
