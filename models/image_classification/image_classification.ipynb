{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb torchvision wandb-workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Demo \u2014 W&B \uc804\uccb4 \uae30\ub2a5 \uccb4\ud5d8\n",
    "\n",
    "## \uac1c\uc694\n",
    "\n",
    "\uc774 \ub178\ud2b8\ubd81\uc740 **CIFAR-10** \ub370\uc774\ud130\uc14b\uacfc **ResNet-18** \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0 \ubd84\ub958\ub97c \uc218\ud589\ud558\uba74\uc11c,\n",
    "W&B(Weights & Biases)\uc758 \ud575\uc2ec \uae30\ub2a5\uc744 \uc804\ubd80 \uccb4\ud5d8\ud569\ub2c8\ub2e4.\n",
    "\n",
    "## \ub2e4\ub8e8\ub294 W&B \uae30\ub2a5\n",
    "\n",
    "| \uae30\ub2a5 | \uc124\uba85 |\n",
    "|------|------|\n",
    "| **Experiment Tracking** | \ud559\uc2b5 \uba54\ud2b8\ub9ad \uc2e4\uc2dc\uac04 \ucd94\uc801 (`wandb.init`, `wandb.log`, `wandb.config`) |\n",
    "| **Media Logging** | \uc774\ubbf8\uc9c0 \ub85c\uae45 (`wandb.Image`) |\n",
    "| **Tables** | \ub370\uc774\ud130\uc14b \ubbf8\ub9ac\ubcf4\uae30 \ubc0f \uc608\uce21 \uacb0\uacfc \ube44\uad50 (`wandb.Table`) |\n",
    "| **Artifacts** | \ub370\uc774\ud130\uc14b/\ubaa8\ub378 \ubc84\uc800\ub2dd \ubc0f \uacc4\ubcf4(lineage) \ucd94\uc801 |\n",
    "| **Model Registry** | \ubaa8\ub378 \ub4f1\ub85d \ubc0f alias \uad00\ub9ac (staging/production) |\n",
    "| **Sweeps** | \ubca0\uc774\uc9c0\uc548 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ucd5c\uc801\ud654 |\n",
    "| **Reports** | \ud504\ub85c\uadf8\ub798\ubc0d \ubc29\uc2dd \uc2e4\ud5d8 \ub9ac\ud3ec\ud2b8 \uc0dd\uc131 |\n",
    "\n",
    "## \ub370\uc774\ud130\uc14b\n",
    "- **CIFAR-10**: 60,000\uc7a5 (32\u00d732 RGB), 10\uac1c \ud074\ub798\uc2a4\n",
    "- torchvision \ub0b4\uc7a5 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubcc4\ub3c4 \ub2e4\uc6b4\ub85c\ub4dc \ubd88\ud544\uc694\n",
    "\n",
    "## \ubaa8\ub378\n",
    "- **ResNet-18** (ImageNet pretrained \u2192 CIFAR-10 fine-tune)\n",
    "- 32\u00d732 \uc785\ub825\uc5d0 \ub9de\uac8c conv1 \ubc0f maxpool \uc218\uc815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import random\n",
    "import time\n",
    "\n",
    "# === \ud559\uc2b5 \uc124\uc815 ===\n",
    "CONFIG = {\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 5,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"num_classes\": 10,\n",
    "    \"img_size\": 32,\n",
    "    \"model_name\": \"resnet18\",\n",
    "    \"dataset\": \"cifar10\",\n",
    "}\n",
    "\n",
    "CIFAR10_CLASSES = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \ub370\uc774\ud130 \ub85c\ub4dc + Transform + DataLoader ===\n",
    "\n",
    "# CIFAR-10 \uc804\uc6a9 \uc815\uaddc\ud654 \uac12 (\uc774\ubbf8\uc9c0\ub137 \uac12\uacfc \ub2e4\ub984)\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=CONFIG[\"batch_size\"], shuffle=True, num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(trainset)}\uc7a5, Test: {len(testset)}\uc7a5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \ub370\uc774\ud130\uc14b Artifact \uc0dd\uc131 ===\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"wandb-e2e-demo-image-classification\",\n",
    "    config=CONFIG,\n",
    "    job_type=\"data-versioning\",\n",
    "    name=\"cifar10-data-versioning\",\n",
    ")\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    \"cifar10\",\n",
    "    type=\"dataset\",\n",
    "    description=\"CIFAR-10 dataset (torchvision)\",\n",
    "    metadata={\n",
    "        \"num_train\": len(trainset),\n",
    "        \"num_test\": len(testset),\n",
    "        \"num_classes\": 10,\n",
    "        \"image_size\": \"32x32\",\n",
    "        \"classes\": CIFAR10_CLASSES,\n",
    "        \"source\": \"torchvision.datasets.CIFAR10\",\n",
    "    },\n",
    ")\n",
    "artifact.add_dir(\"./data/cifar-10-batches-py\")\n",
    "run.log_artifact(artifact)\n",
    "print(\"\ub370\uc774\ud130\uc14b Artifact \ub85c\uae45 \uc644\ub8cc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \uc0d8\ud50c \uc774\ubbf8\uc9c0 wandb.Table \uc2dc\uac01\ud654 ===\n",
    "\n",
    "# \uc2dc\uac01\ud654\uc6a9\uc73c\ub85c \uc815\uaddc\ud654 \uc548 \ub41c \uc6d0\ubcf8 \ub370\uc774\ud130 \ub85c\ub4dc\n",
    "raw_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=False, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# \ud074\ub798\uc2a4\ubcc4 5\uc7a5 = \ucd1d 50\uc7a5\n",
    "table = wandb.Table(columns=[\"Image\", \"Label\", \"Label_ID\"])\n",
    "\n",
    "class_indices = {i: [] for i in range(10)}\n",
    "for idx, (_, label) in enumerate(raw_dataset):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "for class_id in range(10):\n",
    "    samples = random.sample(class_indices[class_id], 5)\n",
    "    for idx in samples:\n",
    "        img, label = raw_dataset[idx]\n",
    "        table.add_data(wandb.Image(img), CIFAR10_CLASSES[label], label)\n",
    "\n",
    "wandb.log({\"dataset_preview\": table})\n",
    "wandb.finish()\n",
    "print(\"\ub370\uc774\ud130\uc14b \ubbf8\ub9ac\ubcf4\uae30 \ud14c\uc774\ube14 \ub85c\uae45 \uc644\ub8cc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \ubaa8\ub378 \uc815\uc758 (ResNet-18, CIFAR-10\uc6a9 \uc218\uc815) ===\n",
    "\n",
    "def create_model(num_classes=10):\n",
    "    \"\"\"\n",
    "    CIFAR-10(32x32) \uc785\ub825\uc5d0 \ub9de\uac8c \uc218\uc815\ud55c ResNet-18.\n",
    "    \n",
    "    \ud45c\uc900 ResNet-18\uc740 224x224\uc6a9\uc73c\ub85c conv1(7x7, stride=2) + maxpool(3x3, stride=2)\uac00\n",
    "    32x32 \uc785\ub825\uc744 1x1\ub85c \ucd95\uc18c\uc2dc\ucf1c \ud559\uc2b5\uc774 \ubd88\uac00\ub2a5\ud574\uc9d0.\n",
    "    \uc218\uc815: conv1 -> 3x3, stride=1, padding=1 / maxpool -> Identity\n",
    "    \"\"\"\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = create_model(CONFIG[\"num_classes\"]).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \ud559\uc2b5 \ub8e8\ud504 ===\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"wandb-e2e-demo-image-classification\",\n",
    "    config=CONFIG,\n",
    "    job_type=\"training\",\n",
    "    name=\"resnet18-cifar10-baseline\",\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if CONFIG[\"optimizer\"] == \"adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"lr\"])\n",
    "elif CONFIG[\"optimizer\"] == \"sgd\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=CONFIG[\"lr\"], momentum=0.9, weight_decay=5e-4)\n",
    "elif CONFIG[\"optimizer\"] == \"adamw\":\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"], weight_decay=1e-2)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"])\n",
    "\n",
    "# \ubaa8\ub378 gradient/parameter \ub85c\uae45\n",
    "wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            wandb.log({\n",
    "                \"train/batch_loss\": loss.item(),\n",
    "                \"train/batch_acc\": 100.0 * predicted.eq(targets).sum().item() / targets.size(0),\n",
    "            })\n",
    "\n",
    "    return running_loss / len(loader), 100.0 * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return running_loss / len(loader), 100.0 * correct / total\n",
    "\n",
    "\n",
    "# \uba54\uc778 \ud559\uc2b5 \ub8e8\ud504\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(CONFIG[\"epochs\"]):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, trainloader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, testloader, criterion)\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Epoch \ub808\ubca8 \uba54\ud2b8\ub9ad \ub85c\uae45\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train/loss\": train_loss,\n",
    "        \"train/acc\": train_acc,\n",
    "        \"val/loss\": val_loss,\n",
    "        \"val/acc\": val_acc,\n",
    "        \"lr\": scheduler.get_last_lr()[0],\n",
    "        \"epoch_time_sec\": epoch_time,\n",
    "    })\n",
    "\n",
    "    # \uc608\uce21 \uc774\ubbf8\uc9c0 \ub85c\uae45 (denormalize \ud544\uc218)\n",
    "    model.eval()\n",
    "    images, labels = next(iter(testloader))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        _, preds = outputs.max(1)\n",
    "        preds = preds.cpu()\n",
    "\n",
    "    mean = torch.tensor(CIFAR10_MEAN).view(3, 1, 1)\n",
    "    std = torch.tensor(CIFAR10_STD).view(3, 1, 1)\n",
    "    wandb_images = []\n",
    "    for i in range(8):\n",
    "        img = images[i] * std + mean  # denormalize\n",
    "        img = img.clamp(0, 1)\n",
    "        caption = f\"True: {CIFAR10_CLASSES[labels[i]]} | Pred: {CIFAR10_CLASSES[preds[i]]}\"\n",
    "        wandb_images.append(wandb.Image(img, caption=caption))\n",
    "    wandb.log({\"predictions\": wandb_images})\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{CONFIG['epochs']}] \"\n",
    "        f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "        f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\"\n",
    "    )\n",
    "\n",
    "wandb.summary[\"best_val_acc\"] = best_acc\n",
    "print(f\"\\n\ud559\uc2b5 \uc644\ub8cc! Best Val Acc: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \uac80\uc99d \uacb0\uacfc wandb.Table ===\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# \uc2dc\uac01\ud654\uc6a9 \uc6d0\ubcf8 \ub370\uc774\ud130\n",
    "raw_testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=False, transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "columns = [\"Image\", \"True Label\", \"Predicted Label\", \"Correct\", \"Confidence\"]\n",
    "for cls in CIFAR10_CLASSES:\n",
    "    columns.append(f\"P({cls})\")\n",
    "\n",
    "results_table = wandb.Table(columns=columns)\n",
    "num_samples = 200\n",
    "indices = random.sample(range(len(testset)), num_samples)\n",
    "\n",
    "for idx in indices:\n",
    "    img_raw, label = raw_testset[idx]\n",
    "    img_norm, _ = testset[idx]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_norm.unsqueeze(0).to(device))\n",
    "        probs = torch.softmax(output, dim=1)[0].cpu()\n",
    "        pred = probs.argmax().item()\n",
    "        confidence = probs[pred].item()\n",
    "\n",
    "    row = [\n",
    "        wandb.Image(img_raw),\n",
    "        CIFAR10_CLASSES[label],\n",
    "        CIFAR10_CLASSES[pred],\n",
    "        label == pred,\n",
    "        round(confidence, 4),\n",
    "    ]\n",
    "    for p in probs.tolist():\n",
    "        row.append(round(p, 4))\n",
    "\n",
    "    results_table.add_data(*row)\n",
    "\n",
    "wandb.log({\"test_predictions\": results_table})\n",
    "print(f\"\ud14c\uc2a4\ud2b8 \uc608\uce21 \uacb0\uacfc {num_samples}\uac74 \ub85c\uae45 \uc644\ub8cc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === \ubaa8\ub378 Artifact \uc800\uc7a5 ===\n",
    "\n",
    "model_artifact = wandb.Artifact(\n",
    "    \"resnet18-cifar10\",\n",
    "    type=\"model\",\n",
    "    description=\"ResNet-18 fine-tuned on CIFAR-10\",\n",
    "    metadata={\n",
    "        \"model_type\": \"classification\",\n",
    "        \"model_architecture\": \"resnet18\",\n",
    "        \"dataset\": \"cifar10\",\n",
    "        \"num_classes\": 10,\n",
    "        \"best_val_acc\": best_acc,\n",
    "        \"classes\": CIFAR10_CLASSES,\n",
    "        \"framework\": \"pytorch\",\n",
    "        \"input_size\": [3, 32, 32],\n",
    "    },\n",
    ")\n",
    "model_artifact.add_file(\"best_model.pth\", name=\"model.pth\")\n",
    "run.log_artifact(model_artifact)\n",
    "print(\"\ubaa8\ub378 Artifact \ub85c\uae45 \uc644\ub8cc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Registry \ub4f1\ub85d ===\n",
    "\n",
    "run.link_artifact(\n",
    "    model_artifact,\n",
    "    \"model-registry/cifar10-classifier\",\n",
    "    aliases=[\"staging\"],\n",
    ")\n",
    "print(\"Model Registry\uc5d0 'staging' alias\ub85c \ub4f1\ub85d \uc644\ub8cc!\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Sweep\n",
    "\n",
    "**Bayesian \ucd5c\uc801\ud654**\ub97c \uc0ac\uc6a9\ud558\uc5ec \ucd5c\uc801\uc758 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \uc870\ud569\uc744 \ud0d0\uc0c9\ud569\ub2c8\ub2e4.\n",
    "\n",
    "| \ud30c\ub77c\ubbf8\ud130 | \ud0d0\uc0c9 \ubc94\uc704 |\n",
    "|-----------|------------|\n",
    "| Learning Rate | 1e-5 ~ 1e-2 (log uniform) |\n",
    "| Batch Size | 32, 64, 128 |\n",
    "| Optimizer | Adam, SGD, AdamW |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sweep \uc124\uc815 \ubc0f \uc2e4\ud589 ===\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val/acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"min\": 1e-5, \"max\": 1e-2, \"distribution\": \"log_uniform_values\"},\n",
    "        \"batch_size\": {\"values\": [32, 64, 128]},\n",
    "        \"optimizer\": {\"values\": [\"adam\", \"sgd\", \"adamw\"]},\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def sweep_train():\n",
    "    \"\"\"Sweep \ud559\uc2b5 \ud568\uc218 (\uc778\uc790 \uc5c6\uc74c \u2014 wandb.agent \uaddc\uce59)\"\"\"\n",
    "    run = wandb.init(config=CONFIG)\n",
    "    config = wandb.config\n",
    "\n",
    "    # Sweep \ud30c\ub77c\ubbf8\ud130\ub85c DataLoader \uc7ac\uc0dd\uc131\n",
    "    sweep_trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=config.batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    sweep_testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=config.batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    # \uac01 trial\ub9c8\ub2e4 \uc0c8 \ubaa8\ub378\n",
    "    sweep_model = create_model(CONFIG[\"num_classes\"]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if config.optimizer == \"adam\":\n",
    "        opt = optim.Adam(sweep_model.parameters(), lr=config.lr)\n",
    "    elif config.optimizer == \"sgd\":\n",
    "        opt = optim.SGD(sweep_model.parameters(), lr=config.lr, momentum=0.9, weight_decay=5e-4)\n",
    "    elif config.optimizer == \"adamw\":\n",
    "        opt = optim.AdamW(sweep_model.parameters(), lr=config.lr, weight_decay=1e-2)\n",
    "\n",
    "    # Sweep\uc5d0\uc11c\ub294 3 epoch\uc73c\ub85c \uc81c\ud55c (\ub370\ubaa8 \uc2dc\uac04 \uc808\uc57d)\n",
    "    for epoch in range(3):\n",
    "        train_loss, train_acc = train_one_epoch(sweep_model, sweep_trainloader, criterion, opt)\n",
    "        val_loss, val_acc = evaluate(sweep_model, sweep_testloader, criterion)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train/loss\": train_loss,\n",
    "            \"train/acc\": train_acc,\n",
    "            \"val/loss\": val_loss,\n",
    "            \"val/acc\": val_acc,\n",
    "        })\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"wandb-e2e-demo-image-classification\")\n",
    "wandb.agent(sweep_id, function=sweep_train, count=5)\n",
    "print(\"Sweep \uc644\ub8cc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Report \uc0dd\uc131 ===\n",
    "\n",
    "import wandb_workspaces.reports.v2 as wr\n",
    "\n",
    "report = wr.Report(\n",
    "    project=\"wandb-e2e-demo-image-classification\",\n",
    "    title=\"CIFAR-10 Image Classification \u2014 \uc2e4\ud5d8 \uacb0\uacfc \ub9ac\ud3ec\ud2b8\",\n",
    "    description=\"ResNet-18 CIFAR-10 fine-tuning \uc2e4\ud5d8 \uacb0\uacfc \ubc0f Sweep \ubd84\uc11d\",\n",
    ")\n",
    "\n",
    "report.blocks = [\n",
    "    wr.TableOfContents(),\n",
    "\n",
    "    wr.H1(\"1. \uc2e4\ud5d8 \uac1c\uc694\"),\n",
    "    wr.P(\n",
    "        \"CIFAR-10 \ub370\uc774\ud130\uc14b\uc5d0 \ub300\ud55c ResNet-18 \uc774\ubbf8\uc9c0 \ubd84\ub958 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \uc815\ub9ac\ud569\ub2c8\ub2e4. \"\n",
    "        \"W&B\uc758 Experiment Tracking, Artifacts, Sweeps, Model Registry \uae30\ub2a5\uc744 \ud65c\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.\"\n",
    "    ),\n",
    "\n",
    "    wr.H1(\"2. \ud559\uc2b5 \uacb0\uacfc\"),\n",
    "    wr.PanelGrid(\n",
    "        runsets=[\n",
    "            wr.Runset(project=\"wandb-e2e-demo-image-classification\")\n",
    "        ],\n",
    "        panels=[\n",
    "            wr.LinePlot(title=\"Training Loss\", x=\"epoch\", y=[\"train/loss\"]),\n",
    "            wr.LinePlot(title=\"Validation Accuracy\", x=\"epoch\", y=[\"val/acc\"]),\n",
    "            wr.LinePlot(title=\"Validation Loss\", x=\"epoch\", y=[\"val/loss\"]),\n",
    "            wr.LinePlot(title=\"Training Accuracy\", x=\"epoch\", y=[\"train/acc\"]),\n",
    "        ],\n",
    "    ),\n",
    "\n",
    "    wr.H1(\"3. Sweep \ubd84\uc11d\"),\n",
    "    wr.P(\"Bayesian \ucd5c\uc801\ud654\ub97c \ud1b5\ud55c \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud0d0\uc0c9 \uacb0\uacfc:\"),\n",
    "    wr.PanelGrid(\n",
    "        runsets=[\n",
    "            wr.Runset(project=\"wandb-e2e-demo-image-classification\")\n",
    "        ],\n",
    "        panels=[\n",
    "            wr.ParallelCoordinatesPlot(\n",
    "                columns=[\n",
    "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::lr\"),\n",
    "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::batch_size\"),\n",
    "                    wr.ParallelCoordinatesPlotColumn(metric=\"c::optimizer\"),\n",
    "                    wr.ParallelCoordinatesPlotColumn(metric=\"val/acc\"),\n",
    "                ],\n",
    "            ),\n",
    "            wr.ScalarChart(title=\"Best Validation Accuracy\", metric=\"val/acc\"),\n",
    "            wr.BarPlot(title=\"Val Accuracy by Run\", metrics=[\"val/acc\"]),\n",
    "        ],\n",
    "    ),\n",
    "\n",
    "    wr.H1(\"4. \ub2e4\uc74c \ub2e8\uacc4\"),\n",
    "    wr.P(\n",
    "        \"\ucd5c\uc801 \ubaa8\ub378\uc744 Model Registry\uc758 'production' alias\ub85c \uc2b9\uaca9\ud558\uc5ec \"\n",
    "        \"\ubc30\ud3ec \ud30c\uc774\ud504\ub77c\uc778\uc744 \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "report.save()\n",
    "print(f\"Report \uc0dd\uc131 \uc644\ub8cc! URL: {report.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"\\n\ub370\ubaa8 \uc644\ub8cc!\")\n",
    "print(\"W&B \ub300\uc2dc\ubcf4\ub4dc\uc5d0\uc11c \uacb0\uacfc\ub97c \ud655\uc778\ud558\uc138\uc694.\")\n",
    "print(\"\\n\ub2e4\uc74c \ub2e8\uacc4: models/automations/automations.ipynb \uc5d0\uc11c \ubaa8\ub378\uc744 'production'\uc73c\ub85c \uc2b9\uaca9\ud558\uc5ec \uc790\ub3d9 \ubc30\ud3ec\ub97c \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}